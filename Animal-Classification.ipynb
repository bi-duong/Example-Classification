{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zsZNNcrsmjmz",
        "outputId": "0a6bc1a1-ec39-4a53-a3d5-8eec77ff7c92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "zip_path = '/content/drive/My Drive/output.zip'\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall('data')"
      ],
      "metadata": {
        "id": "8YiQA1FXm0iA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "zip_path = '/content/drive/My Drive/data/output.zip'\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall('data2')"
      ],
      "metadata": {
        "id": "78l_2kVr5lhd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "from keras.models import Sequential\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.layers.core import Activation\n",
        "from keras.layers.core import Flatten\n",
        "from keras.layers.core import Dropout\n",
        "from keras.layers.core import Dense\n",
        "from keras import backend as K\n",
        "from keras.utils.image_utils import img_to_array\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from imutils import paths\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "import argparse"
      ],
      "metadata": {
        "id": "MCoXKEoFoIMR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleDatasetLoader:\n",
        "    def __init__(self, preprocessors=None):\n",
        "        # Lưu ảnh tiền xử lý\n",
        "        self.preprocessors = preprocessors\n",
        "\n",
        "        # Nếu bước tiền xử lý là None thì khởi tạo danh sách rỗng\n",
        "        if self.preprocessors is None:\n",
        "            self.preprocessors = []\n",
        "\n",
        "    def load(self, imagePaths, verbose=-1):\n",
        "        # Khởi tạo danh sách các đặc trưng và nhãn\n",
        "        data = []\n",
        "        labels = []\n",
        "\n",
        "        # Lặp qua tất cả ảnh đầu vào\n",
        "        for (i, imagePath) in enumerate(imagePaths):\n",
        "            # Nạp ảnh và trích xuất nhãn từ đường dẫn định dạng\n",
        "            # /path/to/dataset/{class}/{image}.jpg\n",
        "            image = cv2.imread(imagePath)\n",
        "            label = imagePath.split(os.path.sep)[-2]\n",
        "            # check to see if our preprocessors are not None\n",
        "            if self.preprocessors is not None:\n",
        "                # Lặp qua tất cả tiền xử lý và áp dụng cho mỗi ảnh\n",
        "                for p in self.preprocessors:\n",
        "                    image = p.preprocess(image)\n",
        "            # Mỗi ảnh được xử lý là vector đặc trưng bằng cách\n",
        "            # cập nhật danh sách dữ liệu cùng với nhãn\n",
        "            data.append(image)\n",
        "            labels.append(label)\n",
        "\n",
        "            # Hiển thị ảnh cập nhật\n",
        "            if verbose > 0 and i > 0 and (i + 1) % verbose == 0:\n",
        "               print(\"[INFO] Đã xử lý {}/{}\".format(i + 1,len(imagePaths)))\n",
        "                # Trả về dữ liệu kiểu tuple gồm dữ liệu và nhãn\n",
        "        return (np.array(data), np.array(labels))"
      ],
      "metadata": {
        "id": "C29VN9KYoL13"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ImageToArrayPreprocessor:  # Tạo lớp để chuyển ảnh --> mảng\n",
        "    def __init__(self, dataFormat=None):\n",
        "        # Lưu ảnh đã được định dạng\n",
        "        self.dataFormat = dataFormat\n",
        "\n",
        "    def preprocess(self, image): # Định nghĩa phương thức preprocess trả về mảng\n",
        "        # Hàm img_to_array của Keras\n",
        "        return img_to_array(image, data_format=self.dataFormat)\n",
        "class SimplePreprocessor:\n",
        "    def __init__(self, width, height, inter=cv2.INTER_AREA):\n",
        "        # Lưu image width, height và interpolation\n",
        "        self.width = width\n",
        "        self.height = height\n",
        "        self.inter = inter\n",
        "\n",
        "    def preprocess(self, image):\n",
        "        # Trả về ảnh có kích thước đã thay đổi\n",
        "        return cv2.resize(image, (self.width, self.height), interpolation=self.inter)"
      ],
      "metadata": {
        "id": "yGh6L8Y7oUvG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MiniVGGNet:\n",
        "    @staticmethod\n",
        "    def build(width, height, depth, classes):\n",
        "        # Khởi tạo mô hình, shape ảnh đầu vào và số kênh của ảnh đầu vào\n",
        "        model = Sequential()\n",
        "        input_shape = (height, width, depth)\n",
        "        channel_dim = -1  # chỉ số của số kênh ảnh đầu vào\n",
        "                          # giá trị -1 ý muốn nói chỉ số kênh nằm cuối cùng\n",
        "                          # của danh sách chứa dữ liệu ảnh đầu vào\n",
        "\n",
        "        # sử dụng 'channels_first' để cập nhật shape và số kênh ảnh đầu vào\n",
        "        if K.image_data_format() == 'channels_first':\n",
        "            input_shape = (depth, height, width)\n",
        "            channel_dim = 1\n",
        "\n",
        "        # Chuỗi layer đầu tiên  CONV => RELU => CONV => RELU => POOL\n",
        "        model.add(Conv2D(32, (3, 3), padding='same', input_shape=input_shape))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization(axis=channel_dim))\n",
        "        model.add(Conv2D(32, (3, 3), padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization(axis=channel_dim))\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "        model.add(Dropout(0.25))\n",
        "\n",
        "        # Chuỗi layer thứ hai CONV => RELU => CONV => RELU => POOL\n",
        "        model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization(axis=channel_dim))\n",
        "        model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization(axis=channel_dim))\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "        model.add(Dropout(0.25))\n",
        "\n",
        "        # Thiết lập FC thứ nhất => RELU layers\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(512))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(0.5))   # Dropout 50%\n",
        "\n",
        "        # THiết lập FC thứ hai => Hàm phân lớp Softmax\n",
        "        model.add(Dense(classes))\n",
        "        model.add(Activation('softmax'))\n",
        "\n",
        "        # Trả về kiến trúc mạng/mô hình\n",
        "        return model"
      ],
      "metadata": {
        "id": "oVK0l-GDohlG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LMbrkKtSJjZn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "code thêm"
      ],
      "metadata": {
        "id": "_YhRJSWtuwzV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from multiprocessing import Pool\n",
        "def load_image(imagePath):\n",
        "    image = cv2.imread(imagePath)\n",
        "    image = cv2.resize(image, (224, 224))\n",
        "    return image\n",
        "imagePaths = list(paths.list_images(\"data/output\"))\n",
        "\n",
        "    # Sử dụng multiprocessing để nạp ảnh đồng thời\n",
        "with Pool() as p:\n",
        "    data = p.map(load_image, imagePaths)\n",
        "\n",
        "    # Chuyển đổi ảnh sang mảng và chuẩn bị dữ liệu\n",
        "data = np.array(data) / 255.0\n",
        "labels = [p.split(os.path.sep)[-2] for p in imagePaths]\n",
        "labels = np.array(labels)"
      ],
      "metadata": {
        "id": "uIJ1QZbctQiA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "code gốc"
      ],
      "metadata": {
        "id": "79sGDzrJuy-i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "imagePaths = list(paths.list_images(\"data/output\"))\n",
        "\n",
        "# Bước 1. Chuẩn bị dữ liệu\n",
        "# Khởi tạo tiền xử lý ảnh\n",
        "sp = SimplePreprocessor(32, 32) # Thiết lập kích thước ảnh 32 x 32\n",
        "iap = ImageToArrayPreprocessor() # Gọi hàm để chuyển ảnh sang mảng\n",
        "\n",
        "# Nạp dataset từ đĩa\n",
        "print(\"[INFO] Nạp ảnh...\")\n",
        "\n",
        "sdl = SimpleDatasetLoader(preprocessors=[sp, iap])\n",
        "(data, labels) = sdl.load(imagePaths, verbose=500)\n",
        "data = data.astype(\"float\") / 255.0"
      ],
      "metadata": {
        "id": "ojez5Aw6rbHt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from keras.optimizers import Adam\n",
        "# Chia tách dữ liệu vào 02 tập, training: 75% và testing: 25%\n",
        "(trainX, testX, trainY, testY) = train_test_split(data, labels,test_size=0.25, random_state=42)\n",
        "# Chuyển dữ liệu nhãn ở số nguyên vào biểu diễn dưới dạng vectors\n",
        "trainY = LabelBinarizer().fit_transform(trainY)\n",
        "testY = LabelBinarizer().fit_transform(testY)\n",
        "\n",
        "# Khởi tạo danh sách các label cho tập dữ liệu flowers\n",
        "label_names = [\"cat\", \"dog\", \"panda\"]\n",
        "\n",
        "# Bước 2: Khởi tạo bộ tối ưu và model\n",
        "print(\"[INFO]: Biên dịch model....\")\n",
        "# Các tham số bộ tối ưu:\n",
        "#   - learning_rate: Tốc dộ học\n",
        "#   - decay: sử dụng để giảm từ từ tốc độ học theo thời gian\n",
        "#            được tính bằng Tốc độ học /tổng epoch. Dùng để tránh overfitting\n",
        "#            và tăng độ chính xác khi tranning\n",
        "#   - momentum: Hệ số quán tính\n",
        "#   - nesterov = True: sử dụng phương pháp tối ưu Nestrov accelerated gradient\n",
        "optimizer = SGD(learning_rate=0.01, momentum=0.9, nesterov=True)\n",
        "\n",
        "model =MiniVGGNet.build(width=32, height=32, depth=3, classes=3)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
        "\n",
        "# Bước 3: Train the network\n",
        "print(\"[INFO]: Đang trainning....\")\n",
        "H = model.fit(trainX, trainY, validation_data=(testX, testY), batch_size=64, epochs=50, verbose=1)\n",
        "\n",
        "\n",
        "model.summary() # Hiển thị tóm tắt các tham số của model\n",
        "\n",
        "# Bước 4: Đánh giá mạng\n",
        "print(\"[INFO]: Đánh giá model....\")\n",
        "predictions = model.predict(testX, batch_size=64)\n",
        "print(classification_report(testY.argmax(axis=1), predictions.argmax(axis=1), target_names=label_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nx4OuM3Vri2-",
        "outputId": "83fd0b97-e2cd-4efb-f93a-d67160f31720"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO]: Biên dịch model....\n",
            "[INFO]: Đang trainning....\n",
            "Epoch 1/50\n",
            "305/305 [==============================] - 7s 14ms/step - loss: 0.9721 - accuracy: 0.5784 - val_loss: 2.0280 - val_accuracy: 0.3741\n",
            "Epoch 2/50\n",
            "305/305 [==============================] - 4s 13ms/step - loss: 0.8130 - accuracy: 0.6308 - val_loss: 1.3343 - val_accuracy: 0.4982\n",
            "Epoch 3/50\n",
            "305/305 [==============================] - 4s 13ms/step - loss: 0.7648 - accuracy: 0.6495 - val_loss: 0.8922 - val_accuracy: 0.6160\n",
            "Epoch 4/50\n",
            "305/305 [==============================] - 4s 12ms/step - loss: 0.6936 - accuracy: 0.6774 - val_loss: 0.6907 - val_accuracy: 0.6575\n",
            "Epoch 5/50\n",
            "305/305 [==============================] - 3s 11ms/step - loss: 0.6477 - accuracy: 0.6986 - val_loss: 0.6831 - val_accuracy: 0.6701\n",
            "Epoch 6/50\n",
            "305/305 [==============================] - 4s 12ms/step - loss: 0.6190 - accuracy: 0.7136 - val_loss: 0.6015 - val_accuracy: 0.7247\n",
            "Epoch 7/50\n",
            "305/305 [==============================] - 4s 13ms/step - loss: 0.5811 - accuracy: 0.7348 - val_loss: 0.5542 - val_accuracy: 0.7421\n",
            "Epoch 8/50\n",
            "305/305 [==============================] - 3s 11ms/step - loss: 0.5554 - accuracy: 0.7506 - val_loss: 0.5553 - val_accuracy: 0.7496\n",
            "Epoch 9/50\n",
            "305/305 [==============================] - 4s 11ms/step - loss: 0.5259 - accuracy: 0.7637 - val_loss: 0.6049 - val_accuracy: 0.7382\n",
            "Epoch 10/50\n",
            "305/305 [==============================] - 4s 13ms/step - loss: 0.5017 - accuracy: 0.7757 - val_loss: 0.5824 - val_accuracy: 0.7413\n",
            "Epoch 11/50\n",
            "305/305 [==============================] - 4s 14ms/step - loss: 0.4868 - accuracy: 0.7835 - val_loss: 0.7224 - val_accuracy: 0.6863\n",
            "Epoch 12/50\n",
            "305/305 [==============================] - 3s 11ms/step - loss: 0.4545 - accuracy: 0.7967 - val_loss: 0.5847 - val_accuracy: 0.7555\n",
            "Epoch 13/50\n",
            "305/305 [==============================] - 4s 13ms/step - loss: 0.4501 - accuracy: 0.8007 - val_loss: 0.5048 - val_accuracy: 0.7744\n",
            "Epoch 14/50\n",
            "305/305 [==============================] - 4s 13ms/step - loss: 0.4232 - accuracy: 0.8175 - val_loss: 0.7896 - val_accuracy: 0.7057\n",
            "Epoch 15/50\n",
            "305/305 [==============================] - 4s 12ms/step - loss: 0.4053 - accuracy: 0.8244 - val_loss: 0.4682 - val_accuracy: 0.7931\n",
            "Epoch 16/50\n",
            "305/305 [==============================] - 4s 13ms/step - loss: 0.3997 - accuracy: 0.8287 - val_loss: 0.5431 - val_accuracy: 0.7559\n",
            "Epoch 17/50\n",
            "305/305 [==============================] - 3s 11ms/step - loss: 0.3844 - accuracy: 0.8341 - val_loss: 0.5135 - val_accuracy: 0.7883\n",
            "Epoch 18/50\n",
            "305/305 [==============================] - 4s 14ms/step - loss: 0.3636 - accuracy: 0.8448 - val_loss: 0.8573 - val_accuracy: 0.6954\n",
            "Epoch 19/50\n",
            "305/305 [==============================] - 4s 13ms/step - loss: 0.3593 - accuracy: 0.8446 - val_loss: 0.5867 - val_accuracy: 0.7627\n",
            "Epoch 20/50\n",
            "305/305 [==============================] - 4s 12ms/step - loss: 0.3363 - accuracy: 0.8598 - val_loss: 0.5481 - val_accuracy: 0.7883\n",
            "Epoch 21/50\n",
            "305/305 [==============================] - 4s 12ms/step - loss: 0.3198 - accuracy: 0.8657 - val_loss: 0.5348 - val_accuracy: 0.7851\n",
            "Epoch 22/50\n",
            "305/305 [==============================] - 4s 12ms/step - loss: 0.3082 - accuracy: 0.8706 - val_loss: 0.4175 - val_accuracy: 0.8254\n",
            "Epoch 23/50\n",
            "305/305 [==============================] - 4s 13ms/step - loss: 0.3081 - accuracy: 0.8704 - val_loss: 0.4899 - val_accuracy: 0.8063\n",
            "Epoch 24/50\n",
            "305/305 [==============================] - 4s 12ms/step - loss: 0.2841 - accuracy: 0.8817 - val_loss: 0.4720 - val_accuracy: 0.8057\n",
            "Epoch 25/50\n",
            "305/305 [==============================] - 4s 13ms/step - loss: 0.2785 - accuracy: 0.8855 - val_loss: 0.9258 - val_accuracy: 0.6773\n",
            "Epoch 26/50\n",
            "305/305 [==============================] - 4s 12ms/step - loss: 0.3034 - accuracy: 0.8748 - val_loss: 0.4961 - val_accuracy: 0.7982\n",
            "Epoch 27/50\n",
            "305/305 [==============================] - 4s 13ms/step - loss: 0.2594 - accuracy: 0.8925 - val_loss: 0.4515 - val_accuracy: 0.8317\n",
            "Epoch 28/50\n",
            "305/305 [==============================] - 4s 13ms/step - loss: 0.2567 - accuracy: 0.8960 - val_loss: 0.5428 - val_accuracy: 0.8014\n",
            "Epoch 29/50\n",
            "305/305 [==============================] - 4s 12ms/step - loss: 0.2365 - accuracy: 0.9058 - val_loss: 0.6170 - val_accuracy: 0.7760\n",
            "Epoch 30/50\n",
            "305/305 [==============================] - 4s 13ms/step - loss: 0.2359 - accuracy: 0.9039 - val_loss: 0.4843 - val_accuracy: 0.8317\n",
            "Epoch 31/50\n",
            "305/305 [==============================] - 4s 12ms/step - loss: 0.2299 - accuracy: 0.9087 - val_loss: 0.5065 - val_accuracy: 0.8168\n",
            "Epoch 32/50\n",
            "305/305 [==============================] - 4s 13ms/step - loss: 0.2127 - accuracy: 0.9124 - val_loss: 0.5427 - val_accuracy: 0.8234\n",
            "Epoch 33/50\n",
            "305/305 [==============================] - 4s 12ms/step - loss: 0.2160 - accuracy: 0.9108 - val_loss: 0.4650 - val_accuracy: 0.8379\n",
            "Epoch 34/50\n",
            "305/305 [==============================] - 4s 12ms/step - loss: 0.2066 - accuracy: 0.9178 - val_loss: 0.5076 - val_accuracy: 0.8223\n",
            "Epoch 35/50\n",
            "305/305 [==============================] - 3s 11ms/step - loss: 0.1929 - accuracy: 0.9221 - val_loss: 0.4972 - val_accuracy: 0.8288\n",
            "Epoch 36/50\n",
            "305/305 [==============================] - 4s 13ms/step - loss: 0.1912 - accuracy: 0.9228 - val_loss: 0.4608 - val_accuracy: 0.8387\n",
            "Epoch 37/50\n",
            "305/305 [==============================] - 4s 12ms/step - loss: 0.1788 - accuracy: 0.9309 - val_loss: 0.6612 - val_accuracy: 0.7901\n",
            "Epoch 38/50\n",
            "305/305 [==============================] - 4s 12ms/step - loss: 0.1750 - accuracy: 0.9340 - val_loss: 0.4953 - val_accuracy: 0.8316\n",
            "Epoch 39/50\n",
            "305/305 [==============================] - 4s 13ms/step - loss: 0.1670 - accuracy: 0.9356 - val_loss: 0.5424 - val_accuracy: 0.8126\n",
            "Epoch 40/50\n",
            "305/305 [==============================] - 4s 13ms/step - loss: 0.1576 - accuracy: 0.9392 - val_loss: 0.4411 - val_accuracy: 0.8448\n",
            "Epoch 41/50\n",
            "305/305 [==============================] - 4s 12ms/step - loss: 0.1534 - accuracy: 0.9406 - val_loss: 0.4631 - val_accuracy: 0.8387\n",
            "Epoch 42/50\n",
            "305/305 [==============================] - 4s 12ms/step - loss: 0.1557 - accuracy: 0.9390 - val_loss: 0.4635 - val_accuracy: 0.8368\n",
            "Epoch 43/50\n",
            "305/305 [==============================] - 4s 13ms/step - loss: 0.1426 - accuracy: 0.9441 - val_loss: 0.8240 - val_accuracy: 0.7499\n",
            "Epoch 44/50\n",
            "305/305 [==============================] - 4s 12ms/step - loss: 0.2610 - accuracy: 0.8971 - val_loss: 0.5139 - val_accuracy: 0.8146\n",
            "Epoch 45/50\n",
            "305/305 [==============================] - 4s 13ms/step - loss: 0.1793 - accuracy: 0.9298 - val_loss: 0.5193 - val_accuracy: 0.8245\n",
            "Epoch 46/50\n",
            "305/305 [==============================] - 4s 13ms/step - loss: 0.1622 - accuracy: 0.9382 - val_loss: 0.6037 - val_accuracy: 0.8133\n",
            "Epoch 47/50\n",
            "305/305 [==============================] - 4s 13ms/step - loss: 0.1723 - accuracy: 0.9334 - val_loss: 0.4967 - val_accuracy: 0.8353\n",
            "Epoch 48/50\n",
            "305/305 [==============================] - 4s 12ms/step - loss: 0.1474 - accuracy: 0.9424 - val_loss: 0.4665 - val_accuracy: 0.8374\n",
            "Epoch 49/50\n",
            "305/305 [==============================] - 4s 12ms/step - loss: 0.1495 - accuracy: 0.9409 - val_loss: 1.3614 - val_accuracy: 0.7447\n",
            "Epoch 50/50\n",
            "305/305 [==============================] - 4s 12ms/step - loss: 0.1437 - accuracy: 0.9457 - val_loss: 0.4782 - val_accuracy: 0.8451\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_13 (Conv2D)          (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " activation_16 (Activation)  (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 32, 32, 32)       128       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " conv2d_14 (Conv2D)          (None, 32, 32, 32)        9248      \n",
            "                                                                 \n",
            " activation_17 (Activation)  (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 32, 32, 32)       128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 16, 16, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 16, 16, 32)        0         \n",
            "                                                                 \n",
            " conv2d_15 (Conv2D)          (None, 16, 16, 64)        18496     \n",
            "                                                                 \n",
            " activation_18 (Activation)  (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 16, 16, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_16 (Conv2D)          (None, 16, 16, 64)        36928     \n",
            "                                                                 \n",
            " activation_19 (Activation)  (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 16, 16, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPooling  (None, 8, 8, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 512)               2097664   \n",
            "                                                                 \n",
            " activation_20 (Activation)  (None, 512)               0         \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 512)              2048      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 3)                 1539      \n",
            "                                                                 \n",
            " activation_21 (Activation)  (None, 3)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,167,587\n",
            "Trainable params: 2,166,179\n",
            "Non-trainable params: 1,408\n",
            "_________________________________________________________________\n",
            "[INFO]: Đánh giá model....\n",
            "102/102 [==============================] - 1s 3ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         cat       0.77      0.86      0.81      2172\n",
            "         dog       0.84      0.72      0.77      2146\n",
            "       panda       0.94      0.95      0.95      2172\n",
            "\n",
            "    accuracy                           0.85      6490\n",
            "   macro avg       0.85      0.84      0.84      6490\n",
            "weighted avg       0.85      0.85      0.84      6490\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from keras.optimizers import Adam\n",
        "# Chia tách dữ liệu vào 02 tập, training: 75% và testing: 25%\n",
        "(trainX, testX, trainY, testY) = train_test_split(data, labels,test_size=0.25, random_state=42)\n",
        "# Chuyển dữ liệu nhãn ở số nguyên vào biểu diễn dưới dạng vectors\n",
        "trainY = LabelBinarizer().fit_transform(trainY)\n",
        "testY = LabelBinarizer().fit_transform(testY)\n",
        "\n",
        "# Khởi tạo danh sách các label cho tập dữ liệu flowers\n",
        "label_names = [\"cat\", \"dog\", \"panda\"]\n",
        "\n",
        "# Bước 2: Khởi tạo bộ tối ưu và model\n",
        "print(\"[INFO]: Biên dịch model....\")\n",
        "# Các tham số bộ tối ưu:\n",
        "#   - learning_rate: Tốc dộ học\n",
        "#   - decay: sử dụng để giảm từ từ tốc độ học theo thời gian\n",
        "#            được tính bằng Tốc độ học /tổng epoch. Dùng để tránh overfitting\n",
        "#            và tăng độ chính xác khi tranning\n",
        "#   - momentum: Hệ số quán tính\n",
        "#   - nesterov = True: sử dụng phương pháp tối ưu Nestrov accelerated gradient\n",
        "optimizer = Adam(learning_rate=0.01)\n",
        "\n",
        "model =MiniVGGNet.build(width=32, height=32, depth=3, classes=3)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
        "\n",
        "# Bước 3: Train the network\n",
        "print(\"[INFO]: Đang trainning....\")\n",
        "H = model.fit(trainX, trainY, validation_data=(testX, testY), batch_size=64, epochs=50, verbose=1)\n",
        "\n",
        "\n",
        "model.summary() # Hiển thị tóm tắt các tham số của model\n",
        "\n",
        "# Bước 4: Đánh giá mạng\n",
        "print(\"[INFO]: Đánh giá model....\")\n",
        "predictions = model.predict(testX, batch_size=64)\n",
        "print(classification_report(testY.argmax(axis=1), predictions.argmax(axis=1), target_names=label_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQZbmy4eMg1e",
        "outputId": "534820d1-aef8-4ae0-9cfa-54b627ac81ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO]: Biên dịch model....\n",
            "[INFO]: Đang trainning....\n",
            "Epoch 1/50\n",
            "305/305 [==============================] - 5s 14ms/step - loss: 0.9767 - accuracy: 0.5861 - val_loss: 0.7944 - val_accuracy: 0.5946\n",
            "Epoch 2/50\n",
            "305/305 [==============================] - 4s 13ms/step - loss: 0.7110 - accuracy: 0.6586 - val_loss: 0.6275 - val_accuracy: 0.6943\n",
            "Epoch 3/50\n",
            "305/305 [==============================] - 3s 11ms/step - loss: 0.6204 - accuracy: 0.7084 - val_loss: 1.2698 - val_accuracy: 0.4911\n",
            "Epoch 4/50\n",
            "305/305 [==============================] - 4s 12ms/step - loss: 0.5651 - accuracy: 0.7405 - val_loss: 0.5392 - val_accuracy: 0.7462\n",
            "Epoch 5/50\n",
            "305/305 [==============================] - 4s 13ms/step - loss: 0.5279 - accuracy: 0.7631 - val_loss: 0.8317 - val_accuracy: 0.6268\n",
            "Epoch 6/50\n",
            "305/305 [==============================] - 4s 13ms/step - loss: 0.5053 - accuracy: 0.7713 - val_loss: 0.8873 - val_accuracy: 0.6626\n",
            "Epoch 7/50\n",
            "305/305 [==============================] - 4s 12ms/step - loss: 0.5022 - accuracy: 0.7771 - val_loss: 0.5303 - val_accuracy: 0.7646\n",
            "Epoch 8/50\n",
            "305/305 [==============================] - 4s 12ms/step - loss: 0.4649 - accuracy: 0.7943 - val_loss: 0.6194 - val_accuracy: 0.7253\n",
            "Epoch 9/50\n",
            "305/305 [==============================] - 4s 12ms/step - loss: 0.4383 - accuracy: 0.8073 - val_loss: 0.5605 - val_accuracy: 0.7632\n",
            "Epoch 10/50\n",
            "305/305 [==============================] - 4s 12ms/step - loss: 0.4144 - accuracy: 0.8172 - val_loss: 0.9798 - val_accuracy: 0.6590\n",
            "Epoch 11/50\n",
            "305/305 [==============================] - 4s 11ms/step - loss: 0.4046 - accuracy: 0.8201 - val_loss: 0.4602 - val_accuracy: 0.7982\n",
            "Epoch 12/50\n",
            "305/305 [==============================] - 4s 13ms/step - loss: 0.3719 - accuracy: 0.8374 - val_loss: 0.7165 - val_accuracy: 0.7570\n",
            "Epoch 13/50\n",
            "305/305 [==============================] - 4s 12ms/step - loss: 0.3636 - accuracy: 0.8456 - val_loss: 0.5046 - val_accuracy: 0.7898\n",
            "Epoch 14/50\n",
            "305/305 [==============================] - 4s 12ms/step - loss: 0.3469 - accuracy: 0.8542 - val_loss: 0.6518 - val_accuracy: 0.7473\n",
            "Epoch 15/50\n",
            "305/305 [==============================] - 3s 11ms/step - loss: 0.3416 - accuracy: 0.8577 - val_loss: 2.9050 - val_accuracy: 0.4989\n",
            "Epoch 16/50\n",
            "305/305 [==============================] - 4s 12ms/step - loss: 0.3331 - accuracy: 0.8608 - val_loss: 0.6330 - val_accuracy: 0.7638\n",
            "Epoch 17/50\n",
            "305/305 [==============================] - 4s 13ms/step - loss: 0.3148 - accuracy: 0.8715 - val_loss: 0.4593 - val_accuracy: 0.8193\n",
            "Epoch 18/50\n",
            "305/305 [==============================] - 4s 12ms/step - loss: 0.3550 - accuracy: 0.8549 - val_loss: 0.5119 - val_accuracy: 0.7926\n",
            "Epoch 19/50\n",
            "305/305 [==============================] - 4s 12ms/step - loss: 0.2928 - accuracy: 0.8793 - val_loss: 0.4274 - val_accuracy: 0.8230\n",
            "Epoch 20/50\n",
            "305/305 [==============================] - 4s 12ms/step - loss: 0.3028 - accuracy: 0.8766 - val_loss: 0.6010 - val_accuracy: 0.7924\n",
            "Epoch 21/50\n",
            "305/305 [==============================] - 3s 11ms/step - loss: 0.2788 - accuracy: 0.8857 - val_loss: 0.4257 - val_accuracy: 0.8359\n",
            "Epoch 22/50\n",
            "305/305 [==============================] - 4s 12ms/step - loss: 0.2393 - accuracy: 0.9063 - val_loss: 0.5518 - val_accuracy: 0.8108\n",
            "Epoch 23/50\n",
            "305/305 [==============================] - 4s 13ms/step - loss: 0.2430 - accuracy: 0.9039 - val_loss: 0.5176 - val_accuracy: 0.8062\n",
            "Epoch 24/50\n",
            "305/305 [==============================] - 4s 12ms/step - loss: 0.2468 - accuracy: 0.9007 - val_loss: 0.4464 - val_accuracy: 0.8359\n",
            "Epoch 25/50\n",
            "305/305 [==============================] - 3s 11ms/step - loss: 0.2307 - accuracy: 0.9090 - val_loss: 0.4504 - val_accuracy: 0.8308\n",
            "Epoch 26/50\n",
            "305/305 [==============================] - 3s 11ms/step - loss: 0.2128 - accuracy: 0.9158 - val_loss: 0.6508 - val_accuracy: 0.8166\n",
            "Epoch 27/50\n",
            "305/305 [==============================] - 4s 13ms/step - loss: 0.2124 - accuracy: 0.9176 - val_loss: 0.5055 - val_accuracy: 0.8296\n",
            "Epoch 28/50\n",
            "305/305 [==============================] - 4s 13ms/step - loss: 0.2266 - accuracy: 0.9126 - val_loss: 0.4719 - val_accuracy: 0.8425\n",
            "Epoch 29/50\n",
            "305/305 [==============================] - 3s 11ms/step - loss: 0.2144 - accuracy: 0.9199 - val_loss: 0.4362 - val_accuracy: 0.8337\n",
            "Epoch 30/50\n",
            "305/305 [==============================] - 4s 12ms/step - loss: 0.1857 - accuracy: 0.9275 - val_loss: 0.5685 - val_accuracy: 0.8017\n",
            "Epoch 31/50\n",
            "305/305 [==============================] - 4s 12ms/step - loss: 0.2223 - accuracy: 0.9139 - val_loss: 0.6004 - val_accuracy: 0.8099\n",
            "Epoch 32/50\n",
            "305/305 [==============================] - 4s 11ms/step - loss: 0.2173 - accuracy: 0.9138 - val_loss: 0.8988 - val_accuracy: 0.7743\n",
            "Epoch 33/50\n",
            "305/305 [==============================] - 3s 11ms/step - loss: 0.1860 - accuracy: 0.9297 - val_loss: 0.5469 - val_accuracy: 0.8153\n",
            "Epoch 34/50\n",
            "305/305 [==============================] - 4s 12ms/step - loss: 0.1628 - accuracy: 0.9378 - val_loss: 0.6978 - val_accuracy: 0.8046\n",
            "Epoch 35/50\n",
            "305/305 [==============================] - 4s 12ms/step - loss: 0.1736 - accuracy: 0.9355 - val_loss: 0.5958 - val_accuracy: 0.8280\n",
            "Epoch 36/50\n",
            "305/305 [==============================] - 4s 11ms/step - loss: 0.1787 - accuracy: 0.9327 - val_loss: 0.5914 - val_accuracy: 0.8333\n",
            "Epoch 37/50\n",
            "305/305 [==============================] - 4s 12ms/step - loss: 0.1489 - accuracy: 0.9444 - val_loss: 0.6035 - val_accuracy: 0.8146\n",
            "Epoch 38/50\n",
            "305/305 [==============================] - 4s 13ms/step - loss: 0.1649 - accuracy: 0.9392 - val_loss: 0.5415 - val_accuracy: 0.8263\n",
            "Epoch 39/50\n",
            "305/305 [==============================] - 4s 13ms/step - loss: 0.1477 - accuracy: 0.9452 - val_loss: 0.6026 - val_accuracy: 0.8193\n",
            "Epoch 40/50\n",
            "305/305 [==============================] - 4s 13ms/step - loss: 0.1501 - accuracy: 0.9439 - val_loss: 0.5396 - val_accuracy: 0.8427\n",
            "Epoch 41/50\n",
            "305/305 [==============================] - 4s 13ms/step - loss: 0.1370 - accuracy: 0.9489 - val_loss: 0.7926 - val_accuracy: 0.8055\n",
            "Epoch 42/50\n",
            "305/305 [==============================] - 4s 12ms/step - loss: 0.1606 - accuracy: 0.9428 - val_loss: 0.6628 - val_accuracy: 0.8096\n",
            "Epoch 43/50\n",
            "305/305 [==============================] - 3s 11ms/step - loss: 0.1403 - accuracy: 0.9514 - val_loss: 0.7413 - val_accuracy: 0.8139\n",
            "Epoch 44/50\n",
            "305/305 [==============================] - 4s 13ms/step - loss: 0.1787 - accuracy: 0.9372 - val_loss: 0.5013 - val_accuracy: 0.8515\n",
            "Epoch 45/50\n",
            "305/305 [==============================] - 4s 13ms/step - loss: 0.1424 - accuracy: 0.9506 - val_loss: 0.5551 - val_accuracy: 0.8424\n",
            "Epoch 46/50\n",
            "305/305 [==============================] - 4s 13ms/step - loss: 0.1276 - accuracy: 0.9531 - val_loss: 0.6128 - val_accuracy: 0.8316\n",
            "Epoch 47/50\n",
            "305/305 [==============================] - 3s 11ms/step - loss: 0.1294 - accuracy: 0.9526 - val_loss: 0.5937 - val_accuracy: 0.8328\n",
            "Epoch 48/50\n",
            "305/305 [==============================] - 4s 11ms/step - loss: 0.1337 - accuracy: 0.9504 - val_loss: 0.5916 - val_accuracy: 0.8433\n",
            "Epoch 49/50\n",
            "305/305 [==============================] - 4s 13ms/step - loss: 0.1221 - accuracy: 0.9568 - val_loss: 1.1319 - val_accuracy: 0.7780\n",
            "Epoch 50/50\n",
            "305/305 [==============================] - 3s 11ms/step - loss: 0.1231 - accuracy: 0.9555 - val_loss: 0.5393 - val_accuracy: 0.8492\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_17 (Conv2D)          (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " activation_22 (Activation)  (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 32, 32, 32)       128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_18 (Conv2D)          (None, 32, 32, 32)        9248      \n",
            "                                                                 \n",
            " activation_23 (Activation)  (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " batch_normalization_6 (Batc  (None, 32, 32, 32)       128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPooling  (None, 16, 16, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 16, 16, 32)        0         \n",
            "                                                                 \n",
            " conv2d_19 (Conv2D)          (None, 16, 16, 64)        18496     \n",
            "                                                                 \n",
            " activation_24 (Activation)  (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " batch_normalization_7 (Batc  (None, 16, 16, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_20 (Conv2D)          (None, 16, 16, 64)        36928     \n",
            "                                                                 \n",
            " activation_25 (Activation)  (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " batch_normalization_8 (Batc  (None, 16, 16, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_8 (MaxPooling  (None, 8, 8, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 512)               2097664   \n",
            "                                                                 \n",
            " activation_26 (Activation)  (None, 512)               0         \n",
            "                                                                 \n",
            " batch_normalization_9 (Batc  (None, 512)              2048      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 3)                 1539      \n",
            "                                                                 \n",
            " activation_27 (Activation)  (None, 3)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,167,587\n",
            "Trainable params: 2,166,179\n",
            "Non-trainable params: 1,408\n",
            "_________________________________________________________________\n",
            "[INFO]: Đánh giá model....\n",
            "102/102 [==============================] - 0s 2ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         cat       0.84      0.78      0.80      2172\n",
            "         dog       0.76      0.85      0.80      2146\n",
            "       panda       0.97      0.92      0.94      2172\n",
            "\n",
            "    accuracy                           0.85      6490\n",
            "   macro avg       0.85      0.85      0.85      6490\n",
            "weighted avg       0.85      0.85      0.85      6490\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from keras.optimizers import Adam\n",
        "# Chia tách dữ liệu vào 02 tập, training: 75% và testing: 25%\n",
        "(trainX, testX, trainY, testY) = train_test_split(data, labels,test_size=0.25, random_state=42)\n",
        "# Chuyển dữ liệu nhãn ở số nguyên vào biểu diễn dưới dạng vectors\n",
        "trainY = LabelBinarizer().fit_transform(trainY)\n",
        "testY = LabelBinarizer().fit_transform(testY)\n",
        "\n",
        "# Khởi tạo danh sách các label cho tập dữ liệu flowers\n",
        "label_names = [\"cat\", \"dog\", \"panda\"]\n",
        "\n",
        "# Bước 2: Khởi tạo bộ tối ưu và model\n",
        "print(\"[INFO]: Biên dịch model....\")\n",
        "# Các tham số bộ tối ưu:\n",
        "#   - learning_rate: Tốc dộ học\n",
        "#   - decay: sử dụng để giảm từ từ tốc độ học theo thời gian\n",
        "#            được tính bằng Tốc độ học /tổng epoch. Dùng để tránh overfitting\n",
        "#            và tăng độ chính xác khi tranning\n",
        "#   - momentum: Hệ số quán tính\n",
        "#   - nesterov = True: sử dụng phương pháp tối ưu Nestrov accelerated gradient\n",
        "optimizer =  Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-7)\n",
        "\n",
        "model =MiniVGGNet.build(width=32, height=32, depth=3, classes=3)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
        "\n",
        "# Bước 3: Train the network\n",
        "print(\"[INFO]: Đang trainning....\")\n",
        "H = model.fit(trainX, trainY, validation_data=(testX, testY), batch_size=64, epochs=50, verbose=1)\n",
        "\n",
        "\n",
        "model.summary() # Hiển thị tóm tắt các tham số của model\n",
        "\n",
        "# Bước 4: Đánh giá mạng\n",
        "print(\"[INFO]: Đánh giá model....\")\n",
        "predictions = model.predict(testX, batch_size=64)\n",
        "print(classification_report(testY.argmax(axis=1), predictions.argmax(axis=1), target_names=label_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V8BKE_6mNWr_",
        "outputId": "a72c1ea0-940a-4f4f-a6e2-bb0db10bae3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO]: Biên dịch model....\n",
            "[INFO]: Đang trainning....\n",
            "Epoch 1/50\n",
            "305/305 [==============================] - 5s 14ms/step - loss: 0.9538 - accuracy: 0.6113 - val_loss: 8.8464 - val_accuracy: 0.3347\n",
            "Epoch 2/50\n",
            "305/305 [==============================] - 4s 13ms/step - loss: 0.6648 - accuracy: 0.6910 - val_loss: 1.3397 - val_accuracy: 0.4456\n",
            "Epoch 3/50\n",
            "305/305 [==============================] - 4s 12ms/step - loss: 0.5909 - accuracy: 0.7260 - val_loss: 0.6484 - val_accuracy: 0.6932\n",
            "Epoch 4/50\n",
            "305/305 [==============================] - 3s 11ms/step - loss: 0.5490 - accuracy: 0.7474 - val_loss: 0.7347 - val_accuracy: 0.6589\n",
            "Epoch 5/50\n",
            "305/305 [==============================] - 4s 12ms/step - loss: 0.5122 - accuracy: 0.7654 - val_loss: 0.6532 - val_accuracy: 0.7319\n",
            "Epoch 6/50\n",
            "305/305 [==============================] - 4s 12ms/step - loss: 0.4844 - accuracy: 0.7817 - val_loss: 0.5802 - val_accuracy: 0.7436\n",
            "Epoch 7/50\n",
            "305/305 [==============================] - 4s 12ms/step - loss: 0.4635 - accuracy: 0.7918 - val_loss: 0.5666 - val_accuracy: 0.7492\n",
            "Epoch 8/50\n",
            "305/305 [==============================] - 3s 11ms/step - loss: 0.4289 - accuracy: 0.8098 - val_loss: 0.5082 - val_accuracy: 0.7750\n",
            "Epoch 9/50\n",
            "305/305 [==============================] - 4s 12ms/step - loss: 0.4051 - accuracy: 0.8234 - val_loss: 0.5338 - val_accuracy: 0.7778\n",
            "Epoch 10/50\n",
            "305/305 [==============================] - 4s 13ms/step - loss: 0.3987 - accuracy: 0.8249 - val_loss: 0.4742 - val_accuracy: 0.7867\n",
            "Epoch 11/50\n",
            "305/305 [==============================] - 4s 12ms/step - loss: 0.3641 - accuracy: 0.8430 - val_loss: 0.5698 - val_accuracy: 0.7753\n",
            "Epoch 12/50\n",
            "305/305 [==============================] - 3s 11ms/step - loss: 0.3455 - accuracy: 0.8532 - val_loss: 0.5234 - val_accuracy: 0.7929\n",
            "Epoch 13/50\n",
            "305/305 [==============================] - 4s 12ms/step - loss: 0.3238 - accuracy: 0.8638 - val_loss: 0.4371 - val_accuracy: 0.8177\n",
            "Epoch 14/50\n",
            "305/305 [==============================] - 4s 12ms/step - loss: 0.3066 - accuracy: 0.8728 - val_loss: 0.5294 - val_accuracy: 0.7724\n",
            "Epoch 15/50\n",
            "305/305 [==============================] - 4s 12ms/step - loss: 0.2824 - accuracy: 0.8809 - val_loss: 0.8809 - val_accuracy: 0.7035\n",
            "Epoch 16/50\n",
            "305/305 [==============================] - 4s 12ms/step - loss: 0.2726 - accuracy: 0.8850 - val_loss: 0.5090 - val_accuracy: 0.7937\n",
            "Epoch 17/50\n",
            "305/305 [==============================] - 4s 13ms/step - loss: 0.2505 - accuracy: 0.8984 - val_loss: 0.5146 - val_accuracy: 0.8005\n",
            "Epoch 18/50\n",
            "305/305 [==============================] - 4s 13ms/step - loss: 0.2621 - accuracy: 0.8947 - val_loss: 0.4303 - val_accuracy: 0.8304\n",
            "Epoch 19/50\n",
            "305/305 [==============================] - 4s 12ms/step - loss: 0.2256 - accuracy: 0.9090 - val_loss: 0.5435 - val_accuracy: 0.7918\n",
            "Epoch 20/50\n",
            "305/305 [==============================] - 3s 11ms/step - loss: 0.2064 - accuracy: 0.9186 - val_loss: 0.4287 - val_accuracy: 0.8368\n",
            "Epoch 21/50\n",
            "305/305 [==============================] - 4s 13ms/step - loss: 0.1928 - accuracy: 0.9238 - val_loss: 0.5859 - val_accuracy: 0.8049\n",
            "Epoch 22/50\n",
            "305/305 [==============================] - 4s 12ms/step - loss: 0.1882 - accuracy: 0.9250 - val_loss: 0.5135 - val_accuracy: 0.8242\n",
            "Epoch 23/50\n",
            "305/305 [==============================] - 3s 11ms/step - loss: 0.1762 - accuracy: 0.9291 - val_loss: 0.4489 - val_accuracy: 0.8431\n",
            "Epoch 24/50\n",
            "305/305 [==============================] - 4s 12ms/step - loss: 0.1742 - accuracy: 0.9321 - val_loss: 0.5299 - val_accuracy: 0.7980\n",
            "Epoch 25/50\n",
            "305/305 [==============================] - 4s 12ms/step - loss: 0.1759 - accuracy: 0.9336 - val_loss: 0.5223 - val_accuracy: 0.8020\n",
            "Epoch 26/50\n",
            "305/305 [==============================] - 4s 12ms/step - loss: 0.1937 - accuracy: 0.9239 - val_loss: 0.4811 - val_accuracy: 0.8291\n",
            "Epoch 27/50\n",
            "305/305 [==============================] - 3s 11ms/step - loss: 0.1726 - accuracy: 0.9328 - val_loss: 0.4330 - val_accuracy: 0.8354\n",
            "Epoch 28/50\n",
            "305/305 [==============================] - 4s 13ms/step - loss: 0.1432 - accuracy: 0.9445 - val_loss: 0.4858 - val_accuracy: 0.8367\n",
            "Epoch 29/50\n",
            "305/305 [==============================] - 4s 13ms/step - loss: 0.1468 - accuracy: 0.9443 - val_loss: 0.4481 - val_accuracy: 0.8468\n",
            "Epoch 30/50\n",
            "305/305 [==============================] - 3s 11ms/step - loss: 0.1405 - accuracy: 0.9468 - val_loss: 0.5227 - val_accuracy: 0.8317\n",
            "Epoch 31/50\n",
            "305/305 [==============================] - 3s 11ms/step - loss: 0.1287 - accuracy: 0.9520 - val_loss: 0.4434 - val_accuracy: 0.8473\n",
            "Epoch 32/50\n",
            "305/305 [==============================] - 4s 13ms/step - loss: 0.1302 - accuracy: 0.9512 - val_loss: 0.4887 - val_accuracy: 0.8357\n",
            "Epoch 33/50\n",
            "305/305 [==============================] - 3s 11ms/step - loss: 0.1153 - accuracy: 0.9572 - val_loss: 0.5926 - val_accuracy: 0.8145\n",
            "Epoch 34/50\n",
            "305/305 [==============================] - 4s 12ms/step - loss: 0.1235 - accuracy: 0.9538 - val_loss: 0.4886 - val_accuracy: 0.8290\n",
            "Epoch 35/50\n",
            "305/305 [==============================] - 4s 12ms/step - loss: 0.1265 - accuracy: 0.9526 - val_loss: 0.4557 - val_accuracy: 0.8422\n",
            "Epoch 36/50\n",
            "305/305 [==============================] - 4s 13ms/step - loss: 0.1196 - accuracy: 0.9546 - val_loss: 0.5280 - val_accuracy: 0.8294\n",
            "Epoch 37/50\n",
            "305/305 [==============================] - 3s 11ms/step - loss: 0.2205 - accuracy: 0.9208 - val_loss: 0.4379 - val_accuracy: 0.8390\n",
            "Epoch 38/50\n",
            "305/305 [==============================] - 4s 13ms/step - loss: 0.1193 - accuracy: 0.9553 - val_loss: 0.4419 - val_accuracy: 0.8450\n",
            "Epoch 39/50\n",
            "305/305 [==============================] - 4s 13ms/step - loss: 0.1075 - accuracy: 0.9592 - val_loss: 0.4510 - val_accuracy: 0.8552\n",
            "Epoch 40/50\n",
            "305/305 [==============================] - 4s 13ms/step - loss: 0.1035 - accuracy: 0.9605 - val_loss: 0.5622 - val_accuracy: 0.8197\n",
            "Epoch 41/50\n",
            "305/305 [==============================] - 4s 11ms/step - loss: 0.0882 - accuracy: 0.9663 - val_loss: 0.5174 - val_accuracy: 0.8433\n",
            "Epoch 42/50\n",
            "305/305 [==============================] - 3s 11ms/step - loss: 0.0915 - accuracy: 0.9677 - val_loss: 0.4999 - val_accuracy: 0.8353\n",
            "Epoch 43/50\n",
            "305/305 [==============================] - 4s 13ms/step - loss: 0.0781 - accuracy: 0.9721 - val_loss: 0.4927 - val_accuracy: 0.8529\n",
            "Epoch 44/50\n",
            "305/305 [==============================] - 4s 12ms/step - loss: 0.0856 - accuracy: 0.9682 - val_loss: 0.5114 - val_accuracy: 0.8399\n",
            "Epoch 45/50\n",
            "305/305 [==============================] - 3s 11ms/step - loss: 0.0911 - accuracy: 0.9657 - val_loss: 0.5570 - val_accuracy: 0.8424\n",
            "Epoch 46/50\n",
            "305/305 [==============================] - 4s 13ms/step - loss: 0.0840 - accuracy: 0.9692 - val_loss: 0.5170 - val_accuracy: 0.8448\n",
            "Epoch 47/50\n",
            "305/305 [==============================] - 4s 12ms/step - loss: 0.0890 - accuracy: 0.9677 - val_loss: 0.5436 - val_accuracy: 0.8374\n",
            "Epoch 48/50\n",
            "305/305 [==============================] - 3s 11ms/step - loss: 0.0813 - accuracy: 0.9708 - val_loss: 0.5926 - val_accuracy: 0.8245\n",
            "Epoch 49/50\n",
            "305/305 [==============================] - 4s 12ms/step - loss: 0.0747 - accuracy: 0.9720 - val_loss: 0.5092 - val_accuracy: 0.8508\n",
            "Epoch 50/50\n",
            "305/305 [==============================] - 4s 13ms/step - loss: 0.0798 - accuracy: 0.9707 - val_loss: 0.5429 - val_accuracy: 0.8502\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_21 (Conv2D)          (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " activation_28 (Activation)  (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " batch_normalization_10 (Bat  (None, 32, 32, 32)       128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_22 (Conv2D)          (None, 32, 32, 32)        9248      \n",
            "                                                                 \n",
            " activation_29 (Activation)  (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " batch_normalization_11 (Bat  (None, 32, 32, 32)       128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_9 (MaxPooling  (None, 16, 16, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 16, 16, 32)        0         \n",
            "                                                                 \n",
            " conv2d_23 (Conv2D)          (None, 16, 16, 64)        18496     \n",
            "                                                                 \n",
            " activation_30 (Activation)  (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " batch_normalization_12 (Bat  (None, 16, 16, 64)       256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_24 (Conv2D)          (None, 16, 16, 64)        36928     \n",
            "                                                                 \n",
            " activation_31 (Activation)  (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " batch_normalization_13 (Bat  (None, 16, 16, 64)       256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_10 (MaxPoolin  (None, 8, 8, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 512)               2097664   \n",
            "                                                                 \n",
            " activation_32 (Activation)  (None, 512)               0         \n",
            "                                                                 \n",
            " batch_normalization_14 (Bat  (None, 512)              2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_10 (Dropout)        (None, 512)               0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 3)                 1539      \n",
            "                                                                 \n",
            " activation_33 (Activation)  (None, 3)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,167,587\n",
            "Trainable params: 2,166,179\n",
            "Non-trainable params: 1,408\n",
            "_________________________________________________________________\n",
            "[INFO]: Đánh giá model....\n",
            "102/102 [==============================] - 0s 3ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         cat       0.83      0.79      0.81      2172\n",
            "         dog       0.80      0.80      0.80      2146\n",
            "       panda       0.92      0.97      0.94      2172\n",
            "\n",
            "    accuracy                           0.85      6490\n",
            "   macro avg       0.85      0.85      0.85      6490\n",
            "weighted avg       0.85      0.85      0.85      6490\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from keras.optimizers import Adam\n",
        "# Chia tách dữ liệu vào 02 tập, training: 75% và testing: 25%\n",
        "(trainX, testX, trainY, testY) = train_test_split(data, labels,test_size=0.25, random_state=42)\n",
        "# Chuyển dữ liệu nhãn ở số nguyên vào biểu diễn dưới dạng vectors\n",
        "trainY = LabelBinarizer().fit_transform(trainY)\n",
        "testY = LabelBinarizer().fit_transform(testY)\n",
        "\n",
        "# Khởi tạo danh sách các label cho tập dữ liệu flowers\n",
        "label_names = [\"cat\", \"dog\", \"panda\"]\n",
        "\n",
        "# Bước 2: Khởi tạo bộ tối ưu và model\n",
        "print(\"[INFO]: Biên dịch model....\")\n",
        "# Các tham số bộ tối ưu:\n",
        "#   - learning_rate: Tốc dộ học\n",
        "#   - decay: sử dụng để giảm từ từ tốc độ học theo thời gian\n",
        "#            được tính bằng Tốc độ học /tổng epoch. Dùng để tránh overfitting\n",
        "#            và tăng độ chính xác khi tranning\n",
        "#   - momentum: Hệ số quán tính\n",
        "#   - nesterov = True: sử dụng phương pháp tối ưu Nestrov accelerated gradient\n",
        "optimizer =  Adam(learning_rate=0.01, beta_1=0.9, beta_2=0.999, epsilon=1e-7)\n",
        "\n",
        "model =MiniVGGNet.build(width=32, height=32, depth=3, classes=3)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
        "\n",
        "# Bước 3: Train the network\n",
        "print(\"[INFO]: Đang trainning....\")\n",
        "H = model.fit(trainX, trainY, validation_data=(testX, testY), batch_size=64, epochs=50, verbose=1)\n",
        "\n",
        "\n",
        "model.summary() # Hiển thị tóm tắt các tham số của model\n",
        "\n",
        "# Bước 4: Đánh giá mạng\n",
        "print(\"[INFO]: Đánh giá model....\")\n",
        "predictions = model.predict(testX, batch_size=64)\n",
        "print(classification_report(testY.argmax(axis=1), predictions.argmax(axis=1), target_names=label_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfjLqSgUOL5W",
        "outputId": "9351b5ce-15b4-440c-bf81-3bb812977db2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO]: Biên dịch model....\n",
            "[INFO]: Đang trainning....\n",
            "Epoch 1/50\n",
            "305/305 [==============================] - 5s 13ms/step - loss: 0.9742 - accuracy: 0.5892 - val_loss: 1.2765 - val_accuracy: 0.4239\n",
            "Epoch 2/50\n",
            "305/305 [==============================] - 4s 13ms/step - loss: 0.7276 - accuracy: 0.6481 - val_loss: 1.1866 - val_accuracy: 0.5186\n",
            "Epoch 3/50\n",
            "305/305 [==============================] - 4s 12ms/step - loss: 0.6538 - accuracy: 0.6856 - val_loss: 0.8268 - val_accuracy: 0.6055\n",
            "Epoch 4/50\n",
            "305/305 [==============================] - 3s 11ms/step - loss: 0.5970 - accuracy: 0.7206 - val_loss: 0.8987 - val_accuracy: 0.6003\n",
            "Epoch 5/50\n",
            "305/305 [==============================] - 3s 11ms/step - loss: 0.5528 - accuracy: 0.7429 - val_loss: 0.6159 - val_accuracy: 0.6971\n",
            "Epoch 6/50\n",
            "305/305 [==============================] - 4s 13ms/step - loss: 0.5355 - accuracy: 0.7578 - val_loss: 0.5406 - val_accuracy: 0.7518\n",
            "Epoch 7/50\n",
            "305/305 [==============================] - 3s 11ms/step - loss: 0.5154 - accuracy: 0.7679 - val_loss: 0.6645 - val_accuracy: 0.6985\n",
            "Epoch 8/50\n",
            "305/305 [==============================] - 3s 11ms/step - loss: 0.4849 - accuracy: 0.7796 - val_loss: 0.8665 - val_accuracy: 0.6618\n",
            "Epoch 9/50\n",
            "305/305 [==============================] - 4s 12ms/step - loss: 0.4657 - accuracy: 0.7946 - val_loss: 0.7381 - val_accuracy: 0.7205\n",
            "Epoch 10/50\n",
            "305/305 [==============================] - 4s 12ms/step - loss: 0.4509 - accuracy: 0.8021 - val_loss: 0.6974 - val_accuracy: 0.7334\n",
            "Epoch 11/50\n",
            "305/305 [==============================] - 3s 11ms/step - loss: 0.4310 - accuracy: 0.8111 - val_loss: 0.5178 - val_accuracy: 0.7664\n",
            "Epoch 12/50\n",
            "305/305 [==============================] - 3s 11ms/step - loss: 0.4449 - accuracy: 0.8047 - val_loss: 0.5195 - val_accuracy: 0.7794\n",
            "Epoch 13/50\n",
            "305/305 [==============================] - 4s 13ms/step - loss: 0.4092 - accuracy: 0.8234 - val_loss: 0.5891 - val_accuracy: 0.7384\n",
            "Epoch 14/50\n",
            "305/305 [==============================] - 4s 13ms/step - loss: 0.3984 - accuracy: 0.8289 - val_loss: 0.8811 - val_accuracy: 0.6501\n",
            "Epoch 15/50\n",
            "305/305 [==============================] - 4s 12ms/step - loss: 0.3826 - accuracy: 0.8320 - val_loss: 0.4714 - val_accuracy: 0.8015\n",
            "Epoch 16/50\n",
            "305/305 [==============================] - 4s 12ms/step - loss: 0.3524 - accuracy: 0.8516 - val_loss: 0.4703 - val_accuracy: 0.8048\n",
            "Epoch 17/50\n",
            "305/305 [==============================] - 4s 13ms/step - loss: 0.3423 - accuracy: 0.8568 - val_loss: 0.4444 - val_accuracy: 0.8119\n",
            "Epoch 18/50\n",
            "305/305 [==============================] - 4s 13ms/step - loss: 0.3282 - accuracy: 0.8634 - val_loss: 0.9197 - val_accuracy: 0.7248\n",
            "Epoch 19/50\n",
            "305/305 [==============================] - 4s 12ms/step - loss: 0.3681 - accuracy: 0.8454 - val_loss: 0.4732 - val_accuracy: 0.8046\n",
            "Epoch 20/50\n",
            "305/305 [==============================] - 4s 12ms/step - loss: 0.3349 - accuracy: 0.8619 - val_loss: 0.4813 - val_accuracy: 0.7991\n",
            "Epoch 21/50\n",
            "305/305 [==============================] - 4s 13ms/step - loss: 0.3027 - accuracy: 0.8746 - val_loss: 0.5150 - val_accuracy: 0.7961\n",
            "Epoch 22/50\n",
            "305/305 [==============================] - 3s 11ms/step - loss: 0.2869 - accuracy: 0.8826 - val_loss: 0.4918 - val_accuracy: 0.8068\n",
            "Epoch 23/50\n",
            "305/305 [==============================] - 4s 11ms/step - loss: 0.2715 - accuracy: 0.8858 - val_loss: 0.6239 - val_accuracy: 0.7846\n",
            "Epoch 24/50\n",
            "305/305 [==============================] - 4s 12ms/step - loss: 0.2567 - accuracy: 0.8950 - val_loss: 0.4385 - val_accuracy: 0.8344\n",
            "Epoch 25/50\n",
            "305/305 [==============================] - 4s 13ms/step - loss: 0.2475 - accuracy: 0.8979 - val_loss: 0.5710 - val_accuracy: 0.8137\n",
            "Epoch 26/50\n",
            "305/305 [==============================] - 4s 12ms/step - loss: 0.2375 - accuracy: 0.9040 - val_loss: 0.4396 - val_accuracy: 0.8243\n",
            "Epoch 27/50\n",
            "305/305 [==============================] - 3s 11ms/step - loss: 0.2451 - accuracy: 0.9025 - val_loss: 0.4934 - val_accuracy: 0.8203\n",
            "Epoch 28/50\n",
            "305/305 [==============================] - 4s 13ms/step - loss: 0.2339 - accuracy: 0.9055 - val_loss: 0.5200 - val_accuracy: 0.8213\n",
            "Epoch 29/50\n",
            "305/305 [==============================] - 3s 11ms/step - loss: 0.2252 - accuracy: 0.9111 - val_loss: 0.4289 - val_accuracy: 0.8482\n",
            "Epoch 30/50\n",
            "305/305 [==============================] - 3s 11ms/step - loss: 0.2061 - accuracy: 0.9193 - val_loss: 0.5428 - val_accuracy: 0.8112\n",
            "Epoch 31/50\n",
            "305/305 [==============================] - 4s 13ms/step - loss: 0.1970 - accuracy: 0.9249 - val_loss: 0.5856 - val_accuracy: 0.8008\n",
            "Epoch 32/50\n",
            "305/305 [==============================] - 4s 13ms/step - loss: 0.1975 - accuracy: 0.9224 - val_loss: 0.5341 - val_accuracy: 0.8341\n",
            "Epoch 33/50\n",
            "305/305 [==============================] - 3s 11ms/step - loss: 0.1959 - accuracy: 0.9227 - val_loss: 0.5026 - val_accuracy: 0.8408\n",
            "Epoch 34/50\n",
            "305/305 [==============================] - 4s 13ms/step - loss: 0.1850 - accuracy: 0.9286 - val_loss: 0.4802 - val_accuracy: 0.8408\n",
            "Epoch 35/50\n",
            "305/305 [==============================] - 4s 13ms/step - loss: 0.2038 - accuracy: 0.9207 - val_loss: 0.6736 - val_accuracy: 0.7798\n",
            "Epoch 36/50\n",
            "305/305 [==============================] - 4s 13ms/step - loss: 0.1874 - accuracy: 0.9277 - val_loss: 0.5330 - val_accuracy: 0.8159\n",
            "Epoch 37/50\n",
            "305/305 [==============================] - 3s 11ms/step - loss: 0.1722 - accuracy: 0.9337 - val_loss: 0.5872 - val_accuracy: 0.8162\n",
            "Epoch 38/50\n",
            "305/305 [==============================] - 4s 13ms/step - loss: 0.1751 - accuracy: 0.9345 - val_loss: 0.6404 - val_accuracy: 0.8136\n",
            "Epoch 39/50\n",
            "305/305 [==============================] - 4s 13ms/step - loss: 0.1643 - accuracy: 0.9391 - val_loss: 0.5341 - val_accuracy: 0.8194\n",
            "Epoch 40/50\n",
            "305/305 [==============================] - 3s 11ms/step - loss: 0.1823 - accuracy: 0.9307 - val_loss: 0.4439 - val_accuracy: 0.8476\n",
            "Epoch 41/50\n",
            "305/305 [==============================] - 4s 13ms/step - loss: 0.1576 - accuracy: 0.9394 - val_loss: 0.4970 - val_accuracy: 0.8444\n",
            "Epoch 42/50\n",
            "305/305 [==============================] - 4s 13ms/step - loss: 0.2330 - accuracy: 0.9106 - val_loss: 0.4330 - val_accuracy: 0.8561\n",
            "Epoch 43/50\n",
            "305/305 [==============================] - 4s 12ms/step - loss: 0.1615 - accuracy: 0.9391 - val_loss: 0.5864 - val_accuracy: 0.8108\n",
            "Epoch 44/50\n",
            "305/305 [==============================] - 4s 13ms/step - loss: 0.1558 - accuracy: 0.9405 - val_loss: 0.5128 - val_accuracy: 0.8470\n",
            "Epoch 45/50\n",
            "305/305 [==============================] - 4s 12ms/step - loss: 0.1405 - accuracy: 0.9468 - val_loss: 0.5155 - val_accuracy: 0.8513\n",
            "Epoch 46/50\n",
            "305/305 [==============================] - 4s 13ms/step - loss: 0.1481 - accuracy: 0.9477 - val_loss: 0.7558 - val_accuracy: 0.8102\n",
            "Epoch 47/50\n",
            "305/305 [==============================] - 4s 12ms/step - loss: 0.1578 - accuracy: 0.9412 - val_loss: 0.5846 - val_accuracy: 0.8291\n",
            "Epoch 48/50\n",
            "305/305 [==============================] - 4s 12ms/step - loss: 0.1442 - accuracy: 0.9481 - val_loss: 0.4600 - val_accuracy: 0.8584\n",
            "Epoch 49/50\n",
            "305/305 [==============================] - 4s 13ms/step - loss: 0.1316 - accuracy: 0.9523 - val_loss: 0.5731 - val_accuracy: 0.8385\n",
            "Epoch 50/50\n",
            "305/305 [==============================] - 4s 13ms/step - loss: 0.1434 - accuracy: 0.9487 - val_loss: 0.5381 - val_accuracy: 0.8530\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_25 (Conv2D)          (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " activation_34 (Activation)  (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " batch_normalization_15 (Bat  (None, 32, 32, 32)       128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_26 (Conv2D)          (None, 32, 32, 32)        9248      \n",
            "                                                                 \n",
            " activation_35 (Activation)  (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " batch_normalization_16 (Bat  (None, 32, 32, 32)       128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_11 (MaxPoolin  (None, 16, 16, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_11 (Dropout)        (None, 16, 16, 32)        0         \n",
            "                                                                 \n",
            " conv2d_27 (Conv2D)          (None, 16, 16, 64)        18496     \n",
            "                                                                 \n",
            " activation_36 (Activation)  (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " batch_normalization_17 (Bat  (None, 16, 16, 64)       256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_28 (Conv2D)          (None, 16, 16, 64)        36928     \n",
            "                                                                 \n",
            " activation_37 (Activation)  (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " batch_normalization_18 (Bat  (None, 16, 16, 64)       256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_12 (MaxPoolin  (None, 8, 8, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_12 (Dropout)        (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 512)               2097664   \n",
            "                                                                 \n",
            " activation_38 (Activation)  (None, 512)               0         \n",
            "                                                                 \n",
            " batch_normalization_19 (Bat  (None, 512)              2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_13 (Dropout)        (None, 512)               0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 3)                 1539      \n",
            "                                                                 \n",
            " activation_39 (Activation)  (None, 3)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,167,587\n",
            "Trainable params: 2,166,179\n",
            "Non-trainable params: 1,408\n",
            "_________________________________________________________________\n",
            "[INFO]: Đánh giá model....\n",
            "102/102 [==============================] - 0s 3ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         cat       0.81      0.82      0.81      2172\n",
            "         dog       0.81      0.78      0.80      2146\n",
            "       panda       0.93      0.96      0.95      2172\n",
            "\n",
            "    accuracy                           0.85      6490\n",
            "   macro avg       0.85      0.85      0.85      6490\n",
            "weighted avg       0.85      0.85      0.85      6490\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from keras.optimizers import Adam\n",
        "# Chia tách dữ liệu vào 02 tập, training: 75% và testing: 25%\n",
        "(trainX, testX, trainY, testY) = train_test_split(data, labels,test_size=0.25, random_state=42)\n",
        "# Chuyển dữ liệu nhãn ở số nguyên vào biểu diễn dưới dạng vectors\n",
        "trainY = LabelBinarizer().fit_transform(trainY)\n",
        "testY = LabelBinarizer().fit_transform(testY)\n",
        "\n",
        "# Khởi tạo danh sách các label cho tập dữ liệu flowers\n",
        "label_names = [\"cat\", \"dog\", \"panda\"]\n",
        "\n",
        "# Bước 2: Khởi tạo bộ tối ưu và model\n",
        "print(\"[INFO]: Biên dịch model....\")\n",
        "# Các tham số bộ tối ưu:\n",
        "#   - learning_rate: Tốc dộ học\n",
        "#   - decay: sử dụng để giảm từ từ tốc độ học theo thời gian\n",
        "#            được tính bằng Tốc độ học /tổng epoch. Dùng để tránh overfitting\n",
        "#            và tăng độ chính xác khi tranning\n",
        "#   - momentum: Hệ số quán tính\n",
        "#   - nesterov = True: sử dụng phương pháp tối ưu Nestrov accelerated gradient\n",
        "optimizer =  Adam(learning_rate=0.01, beta_1=0.9, beta_2=0.999, epsilon=1e-7)\n",
        "\n",
        "model =MiniVGGNet.build(width=32, height=32, depth=3, classes=3)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
        "\n",
        "# Bước 3: Train the network\n",
        "print(\"[INFO]: Đang trainning....\")\n",
        "H = model.fit(trainX, trainY, validation_data=(testX, testY), batch_size=32, epochs=50, verbose=1)\n",
        "\n",
        "\n",
        "model.summary() # Hiển thị tóm tắt các tham số của model\n",
        "\n",
        "# Bước 4: Đánh giá mạng\n",
        "print(\"[INFO]: Đánh giá model....\")\n",
        "predictions = model.predict(testX, batch_size=32)\n",
        "print(classification_report(testY.argmax(axis=1), predictions.argmax(axis=1), target_names=label_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3QMw4EfPE50",
        "outputId": "ac4a57a5-75f6-4054-da1b-b2192a6eb8e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO]: Biên dịch model....\n",
            "[INFO]: Đang trainning....\n",
            "Epoch 1/50\n",
            "609/609 [==============================] - 7s 9ms/step - loss: 1.0051 - accuracy: 0.5788 - val_loss: 0.7413 - val_accuracy: 0.6265\n",
            "Epoch 2/50\n",
            "609/609 [==============================] - 5s 8ms/step - loss: 0.7106 - accuracy: 0.6556 - val_loss: 0.8269 - val_accuracy: 0.6052\n",
            "Epoch 3/50\n",
            "609/609 [==============================] - 6s 9ms/step - loss: 0.6536 - accuracy: 0.6870 - val_loss: 0.8990 - val_accuracy: 0.5735\n",
            "Epoch 4/50\n",
            "609/609 [==============================] - 5s 8ms/step - loss: 0.6190 - accuracy: 0.7074 - val_loss: 0.6710 - val_accuracy: 0.6766\n",
            "Epoch 5/50\n",
            "609/609 [==============================] - 6s 9ms/step - loss: 0.6479 - accuracy: 0.6930 - val_loss: 0.7138 - val_accuracy: 0.6373\n",
            "Epoch 6/50\n",
            "609/609 [==============================] - 5s 8ms/step - loss: 0.6060 - accuracy: 0.7214 - val_loss: 0.5865 - val_accuracy: 0.7228\n",
            "Epoch 7/50\n",
            "609/609 [==============================] - 5s 8ms/step - loss: 0.5969 - accuracy: 0.7213 - val_loss: 0.6128 - val_accuracy: 0.7256\n",
            "Epoch 8/50\n",
            "609/609 [==============================] - 6s 9ms/step - loss: 0.5998 - accuracy: 0.7181 - val_loss: 0.5586 - val_accuracy: 0.7447\n",
            "Epoch 9/50\n",
            "609/609 [==============================] - 5s 8ms/step - loss: 0.5647 - accuracy: 0.7397 - val_loss: 0.5966 - val_accuracy: 0.7239\n",
            "Epoch 10/50\n",
            "609/609 [==============================] - 5s 8ms/step - loss: 0.5211 - accuracy: 0.7660 - val_loss: 1.8127 - val_accuracy: 0.3502\n",
            "Epoch 11/50\n",
            "609/609 [==============================] - 5s 9ms/step - loss: 0.5481 - accuracy: 0.7532 - val_loss: 0.6176 - val_accuracy: 0.7310\n",
            "Epoch 12/50\n",
            "609/609 [==============================] - 5s 8ms/step - loss: 0.5039 - accuracy: 0.7790 - val_loss: 0.6006 - val_accuracy: 0.7260\n",
            "Epoch 13/50\n",
            "609/609 [==============================] - 5s 8ms/step - loss: 0.4790 - accuracy: 0.7910 - val_loss: 0.4827 - val_accuracy: 0.7838\n",
            "Epoch 14/50\n",
            "609/609 [==============================] - 5s 8ms/step - loss: 0.4790 - accuracy: 0.7912 - val_loss: 0.5901 - val_accuracy: 0.7743\n",
            "Epoch 15/50\n",
            "609/609 [==============================] - 5s 8ms/step - loss: 0.4647 - accuracy: 0.8015 - val_loss: 0.5791 - val_accuracy: 0.7687\n",
            "Epoch 16/50\n",
            "609/609 [==============================] - 5s 9ms/step - loss: 0.4312 - accuracy: 0.8135 - val_loss: 0.4581 - val_accuracy: 0.8003\n",
            "Epoch 17/50\n",
            "609/609 [==============================] - 5s 8ms/step - loss: 0.4295 - accuracy: 0.8170 - val_loss: 0.4848 - val_accuracy: 0.8026\n",
            "Epoch 18/50\n",
            "609/609 [==============================] - 5s 7ms/step - loss: 0.4062 - accuracy: 0.8260 - val_loss: 0.6126 - val_accuracy: 0.7507\n",
            "Epoch 19/50\n",
            "609/609 [==============================] - 5s 9ms/step - loss: 0.3897 - accuracy: 0.8355 - val_loss: 0.4529 - val_accuracy: 0.8131\n",
            "Epoch 20/50\n",
            "609/609 [==============================] - 5s 8ms/step - loss: 0.3740 - accuracy: 0.8454 - val_loss: 0.6409 - val_accuracy: 0.7535\n",
            "Epoch 21/50\n",
            "609/609 [==============================] - 5s 8ms/step - loss: 0.3625 - accuracy: 0.8479 - val_loss: 0.4905 - val_accuracy: 0.8025\n",
            "Epoch 22/50\n",
            "609/609 [==============================] - 5s 9ms/step - loss: 0.3454 - accuracy: 0.8565 - val_loss: 0.4884 - val_accuracy: 0.8125\n",
            "Epoch 23/50\n",
            "609/609 [==============================] - 5s 8ms/step - loss: 0.3370 - accuracy: 0.8631 - val_loss: 0.5140 - val_accuracy: 0.7897\n",
            "Epoch 24/50\n",
            "609/609 [==============================] - 6s 9ms/step - loss: 0.3366 - accuracy: 0.8608 - val_loss: 0.4392 - val_accuracy: 0.8274\n",
            "Epoch 25/50\n",
            "609/609 [==============================] - 5s 8ms/step - loss: 0.3189 - accuracy: 0.8696 - val_loss: 0.6268 - val_accuracy: 0.7818\n",
            "Epoch 26/50\n",
            "609/609 [==============================] - 5s 8ms/step - loss: 0.3157 - accuracy: 0.8725 - val_loss: 0.4851 - val_accuracy: 0.8149\n",
            "Epoch 27/50\n",
            "609/609 [==============================] - 6s 9ms/step - loss: 0.2902 - accuracy: 0.8836 - val_loss: 0.4541 - val_accuracy: 0.8314\n",
            "Epoch 28/50\n",
            "609/609 [==============================] - 5s 8ms/step - loss: 0.2821 - accuracy: 0.8856 - val_loss: 0.4390 - val_accuracy: 0.8216\n",
            "Epoch 29/50\n",
            "609/609 [==============================] - 5s 8ms/step - loss: 0.2737 - accuracy: 0.8887 - val_loss: 0.5612 - val_accuracy: 0.7843\n",
            "Epoch 30/50\n",
            "609/609 [==============================] - 5s 9ms/step - loss: 0.2785 - accuracy: 0.8885 - val_loss: 0.4463 - val_accuracy: 0.8297\n",
            "Epoch 31/50\n",
            "609/609 [==============================] - 5s 8ms/step - loss: 0.2680 - accuracy: 0.8942 - val_loss: 0.4603 - val_accuracy: 0.8365\n",
            "Epoch 32/50\n",
            "609/609 [==============================] - 6s 9ms/step - loss: 0.2622 - accuracy: 0.8974 - val_loss: 1.0131 - val_accuracy: 0.6180\n",
            "Epoch 33/50\n",
            "609/609 [==============================] - 5s 8ms/step - loss: 0.2851 - accuracy: 0.8891 - val_loss: 0.4989 - val_accuracy: 0.8282\n",
            "Epoch 34/50\n",
            "609/609 [==============================] - 5s 8ms/step - loss: 0.2461 - accuracy: 0.9020 - val_loss: 0.6032 - val_accuracy: 0.7878\n",
            "Epoch 35/50\n",
            "609/609 [==============================] - 6s 9ms/step - loss: 0.2475 - accuracy: 0.9031 - val_loss: 0.3831 - val_accuracy: 0.8478\n",
            "Epoch 36/50\n",
            "609/609 [==============================] - 5s 8ms/step - loss: 0.2522 - accuracy: 0.9035 - val_loss: 0.4330 - val_accuracy: 0.8444\n",
            "Epoch 37/50\n",
            "609/609 [==============================] - 5s 8ms/step - loss: 0.2383 - accuracy: 0.9082 - val_loss: 0.6250 - val_accuracy: 0.7871\n",
            "Epoch 38/50\n",
            "609/609 [==============================] - 6s 9ms/step - loss: 0.2355 - accuracy: 0.9082 - val_loss: 0.5519 - val_accuracy: 0.8179\n",
            "Epoch 39/50\n",
            "609/609 [==============================] - 5s 8ms/step - loss: 0.2269 - accuracy: 0.9115 - val_loss: 0.5413 - val_accuracy: 0.8185\n",
            "Epoch 40/50\n",
            "609/609 [==============================] - 6s 9ms/step - loss: 0.2310 - accuracy: 0.9126 - val_loss: 0.4663 - val_accuracy: 0.8376\n",
            "Epoch 41/50\n",
            "609/609 [==============================] - 5s 8ms/step - loss: 0.2279 - accuracy: 0.9101 - val_loss: 0.4992 - val_accuracy: 0.8268\n",
            "Epoch 42/50\n",
            "609/609 [==============================] - 5s 8ms/step - loss: 0.2060 - accuracy: 0.9202 - val_loss: 0.4896 - val_accuracy: 0.8348\n",
            "Epoch 43/50\n",
            "609/609 [==============================] - 6s 9ms/step - loss: 0.2000 - accuracy: 0.9222 - val_loss: 0.4412 - val_accuracy: 0.8444\n",
            "Epoch 44/50\n",
            "609/609 [==============================] - 5s 7ms/step - loss: 0.2069 - accuracy: 0.9213 - val_loss: 0.5340 - val_accuracy: 0.8230\n",
            "Epoch 45/50\n",
            "609/609 [==============================] - 5s 8ms/step - loss: 0.2117 - accuracy: 0.9227 - val_loss: 0.4258 - val_accuracy: 0.8496\n",
            "Epoch 46/50\n",
            "609/609 [==============================] - 5s 9ms/step - loss: 0.2017 - accuracy: 0.9257 - val_loss: 0.5616 - val_accuracy: 0.8294\n",
            "Epoch 47/50\n",
            "609/609 [==============================] - 5s 8ms/step - loss: 0.1913 - accuracy: 0.9266 - val_loss: 0.4709 - val_accuracy: 0.8430\n",
            "Epoch 48/50\n",
            "609/609 [==============================] - 5s 8ms/step - loss: 0.3586 - accuracy: 0.8605 - val_loss: 0.4999 - val_accuracy: 0.8096\n",
            "Epoch 49/50\n",
            "609/609 [==============================] - 5s 9ms/step - loss: 0.2390 - accuracy: 0.9088 - val_loss: 0.4604 - val_accuracy: 0.8384\n",
            "Epoch 50/50\n",
            "609/609 [==============================] - 5s 8ms/step - loss: 0.1857 - accuracy: 0.9276 - val_loss: 0.4690 - val_accuracy: 0.8485\n",
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_29 (Conv2D)          (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " activation_40 (Activation)  (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " batch_normalization_20 (Bat  (None, 32, 32, 32)       128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_30 (Conv2D)          (None, 32, 32, 32)        9248      \n",
            "                                                                 \n",
            " activation_41 (Activation)  (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " batch_normalization_21 (Bat  (None, 32, 32, 32)       128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_13 (MaxPoolin  (None, 16, 16, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_14 (Dropout)        (None, 16, 16, 32)        0         \n",
            "                                                                 \n",
            " conv2d_31 (Conv2D)          (None, 16, 16, 64)        18496     \n",
            "                                                                 \n",
            " activation_42 (Activation)  (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " batch_normalization_22 (Bat  (None, 16, 16, 64)       256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_32 (Conv2D)          (None, 16, 16, 64)        36928     \n",
            "                                                                 \n",
            " activation_43 (Activation)  (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " batch_normalization_23 (Bat  (None, 16, 16, 64)       256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_14 (MaxPoolin  (None, 8, 8, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_15 (Dropout)        (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " flatten_5 (Flatten)         (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 512)               2097664   \n",
            "                                                                 \n",
            " activation_44 (Activation)  (None, 512)               0         \n",
            "                                                                 \n",
            " batch_normalization_24 (Bat  (None, 512)              2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_16 (Dropout)        (None, 512)               0         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 3)                 1539      \n",
            "                                                                 \n",
            " activation_45 (Activation)  (None, 3)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,167,587\n",
            "Trainable params: 2,166,179\n",
            "Non-trainable params: 1,408\n",
            "_________________________________________________________________\n",
            "[INFO]: Đánh giá model....\n",
            "203/203 [==============================] - 1s 2ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         cat       0.81      0.79      0.80      2172\n",
            "         dog       0.79      0.79      0.79      2146\n",
            "       panda       0.93      0.96      0.95      2172\n",
            "\n",
            "    accuracy                           0.85      6490\n",
            "   macro avg       0.85      0.85      0.85      6490\n",
            "weighted avg       0.85      0.85      0.85      6490\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LeNet:\n",
        "    @staticmethod\n",
        "    def build(width, height, depth, classes):\n",
        "        # Khởi tạo mô hình, shape ảnh đầu vào và số kênh của ảnh đầu vào\n",
        "        model = Sequential()\n",
        "        inputShape = (height, width, depth)\n",
        "\n",
        "        # sử dụng 'channels_first' để cập nhật shape và số kênh ảnh đầu vào\n",
        "        if K.image_data_format() == \"channels_first\":\n",
        "            inputShape = (depth, height, width)\n",
        "\n",
        "        # thêm layer Convolutional, Activation (ReLU) và max-pooling\n",
        "        model.add(Conv2D(20, (5, 5), padding=\"same\", input_shape=inputShape))\n",
        "        model.add(Activation(\"relu\"))\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "\n",
        "        # thêm layer Convolutional, Activation (ReLU) và max-pooling\n",
        "        model.add(Conv2D(50, (5, 5), padding=\"same\"))\n",
        "        model.add(Activation(\"relu\"))\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "\n",
        "        # flatten layer trước khi đưa vào Fully Connected (FC) layer\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(500))\n",
        "        model.add(Activation(\"relu\"))\n",
        "\n",
        "        # output layer với softmax activation\n",
        "        model.add(Dense(classes))\n",
        "        model.add(Activation(\"softmax\"))\n",
        "\n",
        "        # trả về kiến trúc mô hình\n",
        "        return model\n"
      ],
      "metadata": {
        "id": "n1BmBgqk2zGm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "\n",
        "def VGG16(input_shape, num_classes):\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, (3, 3), padding='same', input_shape=input_shape))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Conv2D(32, (3, 3), padding='same'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(Conv2D(128, (3, 3), padding='same'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Conv2D(128, (3, 3), padding='same'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(Conv2D(256, (3, 3), padding='same'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Conv2D(256, (3, 3), padding='same'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Conv2D(256, (3, 3), padding='same'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(Conv2D(512, (3, 3), padding='same'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Conv2D(512, (3, 3), padding='same'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Conv2D(512, (3, 3), padding='same'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(Conv2D(512, (3, 3), padding='same'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Conv2D(512, (3, 3), padding='same'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Conv2D(512, (3, 3), padding='same'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(4096))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(4096))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(num_classes))\n",
        "    model.add(Activation('softmax'))\n",
        "    \n",
        "    return model"
      ],
      "metadata": {
        "id": "7LfdfkI6-U4U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imagePaths = list(paths.list_images(\"data/output\"))\n",
        "\n",
        "# Bước 1. Chuẩn bị dữ liệu\n",
        "# Khởi tạo tiền xử lý ảnh\n",
        "sp = SimplePreprocessor(32, 32) # Thiết lập kích thước ảnh 32 x 32\n",
        "iap = ImageToArrayPreprocessor() # Gọi hàm để chuyển ảnh sang mảng\n",
        "\n",
        "# Nạp dataset từ đĩa\n",
        "print(\"[INFO] Nạp ảnh...\")\n",
        "\n",
        "sdl = SimpleDatasetLoader(preprocessors=[sp, iap])\n",
        "(data, labels) = sdl.load(imagePaths, verbose=500)\n",
        "data = data.astype(\"float\") / 255.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_clRUJ3yvoG",
        "outputId": "ab706f2f-e834-49d5-eff9-4c83e76876e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Nạp ảnh...\n",
            "[INFO] Đã xử lý 500/25958\n",
            "[INFO] Đã xử lý 1000/25958\n",
            "[INFO] Đã xử lý 1500/25958\n",
            "[INFO] Đã xử lý 2000/25958\n",
            "[INFO] Đã xử lý 2500/25958\n",
            "[INFO] Đã xử lý 3000/25958\n",
            "[INFO] Đã xử lý 3500/25958\n",
            "[INFO] Đã xử lý 4000/25958\n",
            "[INFO] Đã xử lý 4500/25958\n",
            "[INFO] Đã xử lý 5000/25958\n",
            "[INFO] Đã xử lý 5500/25958\n",
            "[INFO] Đã xử lý 6000/25958\n",
            "[INFO] Đã xử lý 6500/25958\n",
            "[INFO] Đã xử lý 7000/25958\n",
            "[INFO] Đã xử lý 7500/25958\n",
            "[INFO] Đã xử lý 8000/25958\n",
            "[INFO] Đã xử lý 8500/25958\n",
            "[INFO] Đã xử lý 9000/25958\n",
            "[INFO] Đã xử lý 9500/25958\n",
            "[INFO] Đã xử lý 10000/25958\n",
            "[INFO] Đã xử lý 10500/25958\n",
            "[INFO] Đã xử lý 11000/25958\n",
            "[INFO] Đã xử lý 11500/25958\n",
            "[INFO] Đã xử lý 12000/25958\n",
            "[INFO] Đã xử lý 12500/25958\n",
            "[INFO] Đã xử lý 13000/25958\n",
            "[INFO] Đã xử lý 13500/25958\n",
            "[INFO] Đã xử lý 14000/25958\n",
            "[INFO] Đã xử lý 14500/25958\n",
            "[INFO] Đã xử lý 15000/25958\n",
            "[INFO] Đã xử lý 15500/25958\n",
            "[INFO] Đã xử lý 16000/25958\n",
            "[INFO] Đã xử lý 16500/25958\n",
            "[INFO] Đã xử lý 17000/25958\n",
            "[INFO] Đã xử lý 17500/25958\n",
            "[INFO] Đã xử lý 18000/25958\n",
            "[INFO] Đã xử lý 18500/25958\n",
            "[INFO] Đã xử lý 19000/25958\n",
            "[INFO] Đã xử lý 19500/25958\n",
            "[INFO] Đã xử lý 20000/25958\n",
            "[INFO] Đã xử lý 20500/25958\n",
            "[INFO] Đã xử lý 21000/25958\n",
            "[INFO] Đã xử lý 21500/25958\n",
            "[INFO] Đã xử lý 22000/25958\n",
            "[INFO] Đã xử lý 22500/25958\n",
            "[INFO] Đã xử lý 23000/25958\n",
            "[INFO] Đã xử lý 23500/25958\n",
            "[INFO] Đã xử lý 24000/25958\n",
            "[INFO] Đã xử lý 24500/25958\n",
            "[INFO] Đã xử lý 25000/25958\n",
            "[INFO] Đã xử lý 25500/25958\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from keras.optimizers import Adam\n",
        "# Chia tách dữ liệu vào 02 tập, training: 75% và testing: 25%\n",
        "(trainX, testX, trainY, testY) = train_test_split(data, labels,test_size=0.25, random_state=42)\n",
        "# Chuyển dữ liệu nhãn ở số nguyên vào biểu diễn dưới dạng vectors\n",
        "trainY = LabelBinarizer().fit_transform(trainY)\n",
        "testY = LabelBinarizer().fit_transform(testY)\n",
        "\n",
        "# Khởi tạo danh sách các label cho tập dữ liệu flowers\n",
        "label_names = [\"cat\", \"dog\", \"panda\"]\n",
        "\n",
        "# Bước 2: Khởi tạo bộ tối ưu và model\n",
        "print(\"[INFO]: Biên dịch model....\")\n",
        "# Các tham số bộ tối ưu:\n",
        "#   - learning_rate: Tốc dộ học\n",
        "#   - decay: sử dụng để giảm từ từ tốc độ học theo thời gian\n",
        "#            được tính bằng Tốc độ học /tổng epoch. Dùng để tránh overfitting\n",
        "#            và tăng độ chính xác khi tranning\n",
        "#   - momentum: Hệ số quán tính\n",
        "#   - nesterov = True: sử dụng phương pháp tối ưu Nestrov accelerated gradient\n",
        "optimizer = SGD(learning_rate=0.01, momentum=0.9, nesterov=True)\n",
        "\n",
        "input_shape = (32, 32, 3)\n",
        "num_classes = 3\n",
        "\n",
        "model = VGG16(input_shape,num_classes)\n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
        "\n",
        "# Bước 3: Train the network\n",
        "print(\"[INFO]: Đang trainning....\")\n",
        "H = model.fit(trainX, trainY, validation_data=(testX, testY), batch_size=64, epochs=50, verbose=1)\n",
        "\n",
        "\n",
        "model.summary() # Hiển thị tóm tắt các tham số của model\n",
        "\n",
        "# Bước 4: Đánh giá mạng\n",
        "print(\"[INFO]: Đánh giá model....\")\n",
        "predictions = model.predict(testX, batch_size=64)\n",
        "print(classification_report(testY.argmax(axis=1), predictions.argmax(axis=1), target_names=label_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "euoidgWhxjb2",
        "outputId": "d17b9d10-602d-4841-b682-76d63e3cf1f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO]: Biên dịch model....\n",
            "[INFO]: Đang trainning....\n",
            "Epoch 1/50\n",
            "305/305 [==============================] - 25s 43ms/step - loss: 1.0990 - accuracy: 0.3343 - val_loss: 1.0986 - val_accuracy: 0.3347\n",
            "Epoch 2/50\n",
            "305/305 [==============================] - 12s 39ms/step - loss: 1.0969 - accuracy: 0.3453 - val_loss: 1.0796 - val_accuracy: 0.4488\n",
            "Epoch 3/50\n",
            "305/305 [==============================] - 12s 39ms/step - loss: 1.0142 - accuracy: 0.4601 - val_loss: 1.1154 - val_accuracy: 0.3347\n",
            "Epoch 4/50\n",
            "305/305 [==============================] - 12s 38ms/step - loss: 1.0516 - accuracy: 0.4074 - val_loss: 1.0227 - val_accuracy: 0.4670\n",
            "Epoch 5/50\n",
            "305/305 [==============================] - 12s 40ms/step - loss: 0.8631 - accuracy: 0.5426 - val_loss: 0.7645 - val_accuracy: 0.5867\n",
            "Epoch 6/50\n",
            "305/305 [==============================] - 12s 40ms/step - loss: 0.7529 - accuracy: 0.5873 - val_loss: 0.9197 - val_accuracy: 0.5522\n",
            "Epoch 7/50\n",
            "305/305 [==============================] - 12s 39ms/step - loss: 0.6971 - accuracy: 0.6029 - val_loss: 0.6514 - val_accuracy: 0.6311\n",
            "Epoch 8/50\n",
            "305/305 [==============================] - 12s 40ms/step - loss: 0.6521 - accuracy: 0.6250 - val_loss: 0.9041 - val_accuracy: 0.5322\n",
            "Epoch 9/50\n",
            "305/305 [==============================] - 12s 39ms/step - loss: 0.6167 - accuracy: 0.6498 - val_loss: 0.6227 - val_accuracy: 0.6529\n",
            "Epoch 10/50\n",
            "305/305 [==============================] - 12s 39ms/step - loss: 0.5922 - accuracy: 0.6817 - val_loss: 0.6686 - val_accuracy: 0.6687\n",
            "Epoch 11/50\n",
            "305/305 [==============================] - 12s 40ms/step - loss: 0.5565 - accuracy: 0.7251 - val_loss: 0.5856 - val_accuracy: 0.7088\n",
            "Epoch 12/50\n",
            "305/305 [==============================] - 12s 40ms/step - loss: 0.5126 - accuracy: 0.7588 - val_loss: 0.6275 - val_accuracy: 0.7190\n",
            "Epoch 13/50\n",
            "305/305 [==============================] - 12s 40ms/step - loss: 0.4689 - accuracy: 0.7823 - val_loss: 0.5232 - val_accuracy: 0.7712\n",
            "Epoch 14/50\n",
            "305/305 [==============================] - 12s 39ms/step - loss: 0.4263 - accuracy: 0.8086 - val_loss: 0.6149 - val_accuracy: 0.7042\n",
            "Epoch 15/50\n",
            "305/305 [==============================] - 12s 40ms/step - loss: 0.3843 - accuracy: 0.8319 - val_loss: 0.7386 - val_accuracy: 0.7288\n",
            "Epoch 16/50\n",
            "305/305 [==============================] - 12s 39ms/step - loss: 0.3576 - accuracy: 0.8458 - val_loss: 0.5207 - val_accuracy: 0.7750\n",
            "Epoch 17/50\n",
            "305/305 [==============================] - 12s 40ms/step - loss: 0.3112 - accuracy: 0.8681 - val_loss: 0.5297 - val_accuracy: 0.7815\n",
            "Epoch 18/50\n",
            "305/305 [==============================] - 12s 40ms/step - loss: 0.2789 - accuracy: 0.8859 - val_loss: 0.6210 - val_accuracy: 0.7604\n",
            "Epoch 19/50\n",
            "305/305 [==============================] - 12s 41ms/step - loss: 0.2400 - accuracy: 0.9030 - val_loss: 0.7138 - val_accuracy: 0.7573\n",
            "Epoch 20/50\n",
            "305/305 [==============================] - 12s 41ms/step - loss: 0.2087 - accuracy: 0.9177 - val_loss: 0.7440 - val_accuracy: 0.7866\n",
            "Epoch 21/50\n",
            "305/305 [==============================] - 12s 40ms/step - loss: 0.1678 - accuracy: 0.9347 - val_loss: 1.6603 - val_accuracy: 0.6764\n",
            "Epoch 22/50\n",
            "305/305 [==============================] - 12s 40ms/step - loss: 0.1662 - accuracy: 0.9382 - val_loss: 0.6235 - val_accuracy: 0.8076\n",
            "Epoch 23/50\n",
            "305/305 [==============================] - 12s 41ms/step - loss: 0.1225 - accuracy: 0.9555 - val_loss: 0.6428 - val_accuracy: 0.7912\n",
            "Epoch 24/50\n",
            "305/305 [==============================] - 12s 40ms/step - loss: 0.1053 - accuracy: 0.9606 - val_loss: 0.6361 - val_accuracy: 0.8149\n",
            "Epoch 25/50\n",
            "305/305 [==============================] - 12s 41ms/step - loss: 0.0868 - accuracy: 0.9671 - val_loss: 0.6941 - val_accuracy: 0.8083\n",
            "Epoch 26/50\n",
            "305/305 [==============================] - 12s 41ms/step - loss: 0.0754 - accuracy: 0.9724 - val_loss: 0.7549 - val_accuracy: 0.8112\n",
            "Epoch 27/50\n",
            "305/305 [==============================] - 12s 41ms/step - loss: 0.0817 - accuracy: 0.9700 - val_loss: 0.7432 - val_accuracy: 0.8106\n",
            "Epoch 28/50\n",
            "305/305 [==============================] - 12s 40ms/step - loss: 0.0671 - accuracy: 0.9742 - val_loss: 0.8027 - val_accuracy: 0.8111\n",
            "Epoch 29/50\n",
            "305/305 [==============================] - 12s 40ms/step - loss: 0.0565 - accuracy: 0.9797 - val_loss: 0.7378 - val_accuracy: 0.8123\n",
            "Epoch 30/50\n",
            "305/305 [==============================] - 12s 41ms/step - loss: 0.0443 - accuracy: 0.9844 - val_loss: 0.7271 - val_accuracy: 0.8260\n",
            "Epoch 31/50\n",
            "305/305 [==============================] - 12s 41ms/step - loss: 0.0369 - accuracy: 0.9867 - val_loss: 0.8093 - val_accuracy: 0.8126\n",
            "Epoch 32/50\n",
            "305/305 [==============================] - 12s 41ms/step - loss: 0.0454 - accuracy: 0.9852 - val_loss: 1.2757 - val_accuracy: 0.7664\n",
            "Epoch 33/50\n",
            "305/305 [==============================] - 12s 41ms/step - loss: 0.0466 - accuracy: 0.9832 - val_loss: 0.7978 - val_accuracy: 0.8068\n",
            "Epoch 34/50\n",
            "305/305 [==============================] - 12s 40ms/step - loss: 0.0381 - accuracy: 0.9870 - val_loss: 0.8001 - val_accuracy: 0.8265\n",
            "Epoch 35/50\n",
            "305/305 [==============================] - 12s 41ms/step - loss: 0.0317 - accuracy: 0.9892 - val_loss: 0.7798 - val_accuracy: 0.8248\n",
            "Epoch 36/50\n",
            "305/305 [==============================] - 12s 40ms/step - loss: 0.0215 - accuracy: 0.9934 - val_loss: 0.9126 - val_accuracy: 0.8205\n",
            "Epoch 37/50\n",
            "305/305 [==============================] - 12s 40ms/step - loss: 0.0270 - accuracy: 0.9903 - val_loss: 0.8464 - val_accuracy: 0.8186\n",
            "Epoch 38/50\n",
            "305/305 [==============================] - 13s 41ms/step - loss: 0.0218 - accuracy: 0.9928 - val_loss: 0.7986 - val_accuracy: 0.8206\n",
            "Epoch 39/50\n",
            "305/305 [==============================] - 12s 40ms/step - loss: 0.0218 - accuracy: 0.9928 - val_loss: 0.8321 - val_accuracy: 0.8185\n",
            "Epoch 40/50\n",
            "305/305 [==============================] - 12s 41ms/step - loss: 0.0230 - accuracy: 0.9915 - val_loss: 0.9364 - val_accuracy: 0.8112\n",
            "Epoch 41/50\n",
            "305/305 [==============================] - 12s 40ms/step - loss: 0.0148 - accuracy: 0.9947 - val_loss: 0.9707 - val_accuracy: 0.8234\n",
            "Epoch 42/50\n",
            "305/305 [==============================] - 13s 42ms/step - loss: 0.0246 - accuracy: 0.9923 - val_loss: 0.8209 - val_accuracy: 0.8279\n",
            "Epoch 43/50\n",
            "305/305 [==============================] - 12s 41ms/step - loss: 0.0193 - accuracy: 0.9933 - val_loss: 0.9104 - val_accuracy: 0.8186\n",
            "Epoch 44/50\n",
            "305/305 [==============================] - 12s 40ms/step - loss: 0.0232 - accuracy: 0.9924 - val_loss: 0.8557 - val_accuracy: 0.8163\n",
            "Epoch 45/50\n",
            "305/305 [==============================] - 12s 40ms/step - loss: 0.0151 - accuracy: 0.9956 - val_loss: 1.1192 - val_accuracy: 0.8040\n",
            "Epoch 46/50\n",
            "305/305 [==============================] - 12s 40ms/step - loss: 0.0286 - accuracy: 0.9898 - val_loss: 0.7933 - val_accuracy: 0.8231\n",
            "Epoch 47/50\n",
            "305/305 [==============================] - 12s 40ms/step - loss: 0.0137 - accuracy: 0.9951 - val_loss: 0.9796 - val_accuracy: 0.8117\n",
            "Epoch 48/50\n",
            "305/305 [==============================] - 12s 41ms/step - loss: 0.0191 - accuracy: 0.9937 - val_loss: 0.9978 - val_accuracy: 0.8284\n",
            "Epoch 49/50\n",
            "305/305 [==============================] - 13s 41ms/step - loss: 0.0080 - accuracy: 0.9972 - val_loss: 1.1628 - val_accuracy: 0.8086\n",
            "Epoch 50/50\n",
            "305/305 [==============================] - 12s 40ms/step - loss: 0.0218 - accuracy: 0.9929 - val_loss: 0.9605 - val_accuracy: 0.8282\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " activation (Activation)     (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 32, 32, 32)        9248      \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 16, 16, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 16, 16, 128)       36992     \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 16, 16, 128)       147584    \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 8, 8, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 8, 8, 256)         295168    \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 8, 8, 256)         0         \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 8, 8, 256)         590080    \n",
            "                                                                 \n",
            " activation_5 (Activation)   (None, 8, 8, 256)         0         \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 8, 8, 256)         590080    \n",
            "                                                                 \n",
            " activation_6 (Activation)   (None, 8, 8, 256)         0         \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 4, 4, 256)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 4, 4, 512)         1180160   \n",
            "                                                                 \n",
            " activation_7 (Activation)   (None, 4, 4, 512)         0         \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 4, 4, 512)         2359808   \n",
            "                                                                 \n",
            " activation_8 (Activation)   (None, 4, 4, 512)         0         \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 4, 4, 512)         2359808   \n",
            "                                                                 \n",
            " activation_9 (Activation)   (None, 4, 4, 512)         0         \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 2, 2, 512)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 2, 2, 512)         2359808   \n",
            "                                                                 \n",
            " activation_10 (Activation)  (None, 2, 2, 512)         0         \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 2, 2, 512)         2359808   \n",
            "                                                                 \n",
            " activation_11 (Activation)  (None, 2, 2, 512)         0         \n",
            "                                                                 \n",
            " conv2d_12 (Conv2D)          (None, 2, 2, 512)         2359808   \n",
            "                                                                 \n",
            " activation_12 (Activation)  (None, 2, 2, 512)         0         \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 1, 1, 512)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 512)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 4096)              2101248   \n",
            "                                                                 \n",
            " activation_13 (Activation)  (None, 4096)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 4096)              16781312  \n",
            "                                                                 \n",
            " activation_14 (Activation)  (None, 4096)              0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 3)                 12291     \n",
            "                                                                 \n",
            " activation_15 (Activation)  (None, 3)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 33,544,099\n",
            "Trainable params: 33,544,099\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "[INFO]: Đánh giá model....\n",
            "102/102 [==============================] - 1s 10ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         cat       0.74      0.85      0.79      2172\n",
            "         dog       0.80      0.72      0.76      2146\n",
            "       panda       0.97      0.92      0.94      2172\n",
            "\n",
            "    accuracy                           0.83      6490\n",
            "   macro avg       0.83      0.83      0.83      6490\n",
            "weighted avg       0.83      0.83      0.83      6490\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Input, Conv2D, BatchNormalization, Activation, Add, GlobalAveragePooling2D, Dense\n",
        "from keras.models import Model\n",
        "\n",
        "def mini_resnet(input_shape, num_classes):\n",
        "    # input layer\n",
        "    x_in = Input(shape=input_shape)\n",
        "\n",
        "    # stage 1\n",
        "    x = Conv2D(filters=32, kernel_size=(3, 3), padding='same')(x_in)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    # stage 2\n",
        "    x_shortcut = x\n",
        "    x = Conv2D(filters=32, kernel_size=(3, 3), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2D(filters=32, kernel_size=(3, 3), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Add()([x_shortcut, x])\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    # stage 3\n",
        "    x_shortcut = x\n",
        "    x = Conv2D(filters=64, kernel_size=(3, 3), strides=(2, 2), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2D(filters=64, kernel_size=(3, 3), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    # shortcut path\n",
        "    x_shortcut = Conv2D(filters=64, kernel_size=(1, 1), strides=(2, 2), padding='same')(x_shortcut)\n",
        "    x_shortcut = BatchNormalization()(x_shortcut)\n",
        "\n",
        "    x = Add()([x_shortcut, x])\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    # stage 4\n",
        "    x_shortcut = x\n",
        "    x = Conv2D(filters=128, kernel_size=(3, 3), strides=(2, 2), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2D(filters=128, kernel_size=(3, 3), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    # shortcut path\n",
        "    x_shortcut = Conv2D(filters=128, kernel_size=(1, 1), strides=(2, 2), padding='same')(x_shortcut)\n",
        "    x_shortcut = BatchNormalization()(x_shortcut)\n",
        "\n",
        "    x = Add()([x_shortcut, x])\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    # final stage\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    # create model\n",
        "    model = Model(inputs=x_in, outputs=x, name='mini_resnet')\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "jUFyT_AGJEZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imagePaths = list(paths.list_images(\"data/output\"))\n",
        "\n",
        "# Bước 1. Chuẩn bị dữ liệu\n",
        "# Khởi tạo tiền xử lý ảnh\n",
        "sp = SimplePreprocessor(32, 32) # Thiết lập kích thước ảnh 32 x 32\n",
        "iap = ImageToArrayPreprocessor() # Gọi hàm để chuyển ảnh sang mảng\n",
        "\n",
        "# Nạp dataset từ đĩa\n",
        "print(\"[INFO] Nạp ảnh...\")\n",
        "\n",
        "sdl = SimpleDatasetLoader(preprocessors=[sp, iap])\n",
        "(data, labels) = sdl.load(imagePaths, verbose=500)\n",
        "data = data.astype(\"float\") / 255.0"
      ],
      "metadata": {
        "id": "9E48bnjGJKCL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from keras.optimizers import Adam\n",
        "# Chia tách dữ liệu vào 02 tập, training: 75% và testing: 25%\n",
        "(trainX, testX, trainY, testY) = train_test_split(data, labels,test_size=0.25, random_state=42)\n",
        "# Chuyển dữ liệu nhãn ở số nguyên vào biểu diễn dưới dạng vectors\n",
        "trainY = LabelBinarizer().fit_transform(trainY)\n",
        "testY = LabelBinarizer().fit_transform(testY)\n",
        "\n",
        "# Khởi tạo danh sách các label cho tập dữ liệu flowers\n",
        "label_names = [\"cat\", \"dog\", \"panda\"]\n",
        "\n",
        "# Bước 2: Khởi tạo bộ tối ưu và model\n",
        "print(\"[INFO]: Biên dịch model....\")\n",
        "# Các tham số bộ tối ưu:\n",
        "#   - learning_rate: Tốc dộ học\n",
        "#   - decay: sử dụng để giảm từ từ tốc độ học theo thời gian\n",
        "#            được tính bằng Tốc độ học /tổng epoch. Dùng để tránh overfitting\n",
        "#            và tăng độ chính xác khi tranning\n",
        "#   - momentum: Hệ số quán tính\n",
        "#   - nesterov = True: sử dụng phương pháp tối ưu Nestrov accelerated gradient\n",
        "optimizer = SGD(learning_rate=0.01, momentum=0.9, nesterov=True)\n",
        "\n",
        "input_shape = (32, 32, 3)\n",
        "num_classes = 3\n",
        "\n",
        "model = mini_resnet(input_shape,num_classes)\n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "# Bước 3: Train the network\n",
        "print(\"[INFO]: Đang trainning....\")\n",
        "H = model.fit(trainX, trainY, validation_data=(testX, testY), batch_size=64, epochs=50, verbose=1)\n",
        "\n",
        "\n",
        "model.summary() # Hiển thị tóm tắt các tham số của model\n",
        "\n",
        "# Bước 4: Đánh giá mạng\n",
        "print(\"[INFO]: Đánh giá model....\")\n",
        "predictions = model.predict(testX, batch_size=64)\n",
        "print(classification_report(testY.argmax(axis=1), predictions.argmax(axis=1), target_names=label_names))"
      ],
      "metadata": {
        "id": "Bz8bfb4TLLCb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Input, Conv2D, BatchNormalization, Activation, Add, GlobalAveragePooling2D, Dense, LeakyReLU, Dropout\n",
        "from keras.models import Model\n",
        "\n",
        "def mini_resnet_v2(input_shape, num_classes):\n",
        "    # input layer\n",
        "    x_in = Input(shape=input_shape)\n",
        "\n",
        "    # stage 1\n",
        "    x = Conv2D(filters=32, kernel_size=(3, 3), padding='same')(x_in)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "    # stage 2\n",
        "    x_shortcut = x\n",
        "    x = Conv2D(filters=64, kernel_size=(3, 3), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU(alpha=0.1)(x)\n",
        "    x = Conv2D(filters=64, kernel_size=(3, 3), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    # Add a Conv2D layer to reduce the dimension of x_shortcut\n",
        "    x_shortcut = Conv2D(filters=64, kernel_size=(1, 1), padding='same')(x_shortcut)\n",
        "    x_shortcut = BatchNormalization()(x_shortcut)\n",
        "\n",
        "    x = Add()([x_shortcut, x])\n",
        "    x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "    # stage 3\n",
        "    x_shortcut = x\n",
        "    x = Conv2D(filters=128, kernel_size=(3, 3), strides=(2, 2), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU(alpha=0.1)(x)\n",
        "    x = Conv2D(filters=128, kernel_size=(3, 3), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    # shortcut path\n",
        "    x_shortcut = Conv2D(filters=128, kernel_size=(1, 1), strides=(2, 2), padding='same')(x_shortcut)\n",
        "    x_shortcut = BatchNormalization()(x_shortcut)\n",
        "\n",
        "    x = Add()([x_shortcut, x])\n",
        "    x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "    # stage 4\n",
        "    x_shortcut = x\n",
        "    x = Conv2D(filters=256, kernel_size=(3, 3), strides=(2, 2), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU(alpha=0.1)(x)\n",
        "    x = Conv2D(filters=256, kernel_size=(3, 3), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    # shortcut path\n",
        "    x_shortcut = Conv2D(filters=256, kernel_size=(1, 1), strides=(2, 2), padding='same')(x_shortcut)\n",
        "    x_shortcut = BatchNormalization()(x_shortcut)\n",
        "\n",
        "    x = Add()([x_shortcut, x])\n",
        "    x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "    # global average pooling and output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(units=512)(x)\n",
        "    x = LeakyReLU(alpha=0.1)(x)\n",
        "    x = Dropout(rate=0.5)(x)\n",
        "    x_out = Dense(units=num_classes, activation='softmax')(x)\n",
        "\n",
        "    # model\n",
        "    model = Model(inputs=x_in, outputs=x_out)\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "-vactkXkk8sr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from keras.optimizers import Adam\n",
        "# Chia tách dữ liệu vào 02 tập, training: 75% và testing: 25%\n",
        "(trainX, testX, trainY, testY) = train_test_split(data, labels,test_size=0.25, random_state=42)\n",
        "# Chuyển dữ liệu nhãn ở số nguyên vào biểu diễn dưới dạng vectors\n",
        "trainY = LabelBinarizer().fit_transform(trainY)\n",
        "testY = LabelBinarizer().fit_transform(testY)\n",
        "\n",
        "# Khởi tạo danh sách các label cho tập dữ liệu flowers\n",
        "label_names = [\"cat\", \"dog\", \"panda\"]\n",
        "\n",
        "# Bước 2: Khởi tạo bộ tối ưu và model\n",
        "print(\"[INFO]: Biên dịch model....\")\n",
        "# Các tham số bộ tối ưu:\n",
        "#   - learning_rate: Tốc dộ học\n",
        "#   - decay: sử dụng để giảm từ từ tốc độ học theo thời gian\n",
        "#            được tính bằng Tốc độ học /tổng epoch. Dùng để tránh overfitting\n",
        "#            và tăng độ chính xác khi tranning\n",
        "#   - momentum: Hệ số quán tính\n",
        "#   - nesterov = True: sử dụng phương pháp tối ưu Nestrov accelerated gradient\n",
        "optimizer = SGD(learning_rate=0.01, momentum=0.9, nesterov=True)\n",
        "\n",
        "input_shape = (32, 32, 3)\n",
        "num_classes = 3\n",
        "\n",
        "model = mini_resnet_v2(input_shape,num_classes)\n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "# Bước 3: Train the network\n",
        "print(\"[INFO]: Đang trainning....\")\n",
        "H = model.fit(trainX, trainY, validation_data=(testX, testY), batch_size=64, epochs=50, verbose=1)\n",
        "\n",
        "\n",
        "model.summary() # Hiển thị tóm tắt các tham số của model\n",
        "\n",
        "# Bước 4: Đánh giá mạng\n",
        "print(\"[INFO]: Đánh giá model....\")\n",
        "predictions = model.predict(testX, batch_size=64)\n",
        "print(classification_report(testY.argmax(axis=1), predictions.argmax(axis=1), target_names=label_names))"
      ],
      "metadata": {
        "id": "ZSs-hNGflARY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from keras.optimizers import Adam\n",
        "# Chia tách dữ liệu vào 02 tập, training: 75% và testing: 25%\n",
        "(trainX, testX, trainY, testY) = train_test_split(data, labels,test_size=0.25, random_state=42)\n",
        "# Chuyển dữ liệu nhãn ở số nguyên vào biểu diễn dưới dạng vectors\n",
        "trainY = LabelBinarizer().fit_transform(trainY)\n",
        "testY = LabelBinarizer().fit_transform(testY)\n",
        "\n",
        "# Khởi tạo danh sách các label cho tập dữ liệu flowers\n",
        "label_names = [\"cat\", \"dog\", \"panda\"]\n",
        "\n",
        "# Bước 2: Khởi tạo bộ tối ưu và model\n",
        "print(\"[INFO]: Biên dịch model....\")\n",
        "# Các tham số bộ tối ưu:\n",
        "#   - learning_rate: Tốc dộ học\n",
        "#   - decay: sử dụng để giảm từ từ tốc độ học theo thời gian\n",
        "#            được tính bằng Tốc độ học /tổng epoch. Dùng để tránh overfitting\n",
        "#            và tăng độ chính xác khi tranning\n",
        "#   - momentum: Hệ số quán tính\n",
        "#   - nesterov = True: sử dụng phương pháp tối ưu Nestrov accelerated gradient\n",
        "optimizer = Adam(lr=0.001)\n",
        "\n",
        "input_shape = (32, 32, 3)\n",
        "num_classes = 3\n",
        "\n",
        "model = mini_resnet_v2(input_shape,num_classes)\n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "# Bước 3: Train the network\n",
        "print(\"[INFO]: Đang trainning....\")\n",
        "H = model.fit(trainX, trainY, validation_data=(testX, testY), batch_size=64, epochs=50, verbose=1)\n",
        "\n",
        "\n",
        "model.summary() # Hiển thị tóm tắt các tham số của model\n",
        "\n",
        "# Bước 4: Đánh giá mạng\n",
        "print(\"[INFO]: Đánh giá model....\")\n",
        "predictions = model.predict(testX, batch_size=64)\n",
        "print(classification_report(testY.argmax(axis=1), predictions.argmax(axis=1), target_names=label_names))"
      ],
      "metadata": {
        "id": "Tt1rUCfNAsLx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "# Chia tách dữ liệu vào 02 tập, training: 75% và testing: 25%\n",
        "(trainX, testX, trainY, testY) = train_test_split(data, labels,test_size=0.25, random_state=42)\n",
        "# Chuyển dữ liệu nhãn ở số nguyên vào biểu diễn dưới dạng vectors\n",
        "trainY = LabelBinarizer().fit_transform(trainY)\n",
        "testY = LabelBinarizer().fit_transform(testY)\n",
        "\n",
        "# Khởi tạo danh sách các label cho tập dữ liệu flowers\n",
        "label_names = [\"cat\", \"dog\", \"panda\"]\n",
        "\n",
        "# Bước 2: Khởi tạo bộ tối ưu và model\n",
        "print(\"[INFO]: Biên dịch model....\")\n",
        "# Các tham số bộ tối ưu:\n",
        "#   - learning_rate: Tốc dộ học\n",
        "#   - decay: sử dụng để giảm từ từ tốc độ học theo thời gian\n",
        "#            được tính bằng Tốc độ học /tổng epoch. Dùng để tránh overfitting\n",
        "#            và tăng độ chính xác khi tranning\n",
        "#   - momentum: Hệ số quán tính\n",
        "#   - nesterov = True: sử dụng phương pháp tối ưu Nestrov accelerated gradient\n",
        "optimizer =  RMSprop(lr=0.001, rho=0.9, epsilon=1e-08)\n",
        "\n",
        "model =MiniVGGNet.build(width=32, height=32, depth=3, classes=3)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
        "\n",
        "# Bước 3: Train the network\n",
        "print(\"[INFO]: Đang trainning....\")\n",
        "H = model.fit(trainX, trainY, validation_data=(testX, testY), batch_size=64, epochs=50, verbose=1)\n",
        "\n",
        "\n",
        "model.summary() # Hiển thị tóm tắt các tham số của model\n",
        "\n",
        "# Bước 4: Đánh giá mạng\n",
        "print(\"[INFO]: Đánh giá model....\")\n",
        "predictions = model.predict(testX, batch_size=64)\n",
        "print(classification_report(testY.argmax(axis=1), predictions.argmax(axis=1), target_names=label_names))"
      ],
      "metadata": {
        "id": "Zmym6f5ny4h0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imagePaths = list(paths.list_images(\"data2/output\"))\n",
        "\n",
        "# Bước 1. Chuẩn bị dữ liệu\n",
        "# Khởi tạo tiền xử lý ảnh\n",
        "sp = SimplePreprocessor(32, 32) # Thiết lập kích thước ảnh 32 x 32\n",
        "iap = ImageToArrayPreprocessor() # Gọi hàm để chuyển ảnh sang mảng\n",
        "\n",
        "# Nạp dataset từ đĩa\n",
        "print(\"[INFO] Nạp ảnh...\")\n",
        "\n",
        "sdl = SimpleDatasetLoader(preprocessors=[sp, iap])\n",
        "(data, labels) = sdl.load(imagePaths, verbose=500)\n",
        "data = data.astype(\"float\") / 255.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3uDFhru251ge",
        "outputId": "a6ab7949-ed39-4112-8de4-a1073f518e18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Nạp ảnh...\n",
            "[INFO] Đã xử lý 500/25962\n",
            "[INFO] Đã xử lý 1000/25962\n",
            "[INFO] Đã xử lý 1500/25962\n",
            "[INFO] Đã xử lý 2000/25962\n",
            "[INFO] Đã xử lý 2500/25962\n",
            "[INFO] Đã xử lý 3000/25962\n",
            "[INFO] Đã xử lý 3500/25962\n",
            "[INFO] Đã xử lý 4000/25962\n",
            "[INFO] Đã xử lý 4500/25962\n",
            "[INFO] Đã xử lý 5000/25962\n",
            "[INFO] Đã xử lý 5500/25962\n",
            "[INFO] Đã xử lý 6000/25962\n",
            "[INFO] Đã xử lý 6500/25962\n",
            "[INFO] Đã xử lý 7000/25962\n",
            "[INFO] Đã xử lý 7500/25962\n",
            "[INFO] Đã xử lý 8000/25962\n",
            "[INFO] Đã xử lý 8500/25962\n",
            "[INFO] Đã xử lý 9000/25962\n",
            "[INFO] Đã xử lý 9500/25962\n",
            "[INFO] Đã xử lý 10000/25962\n",
            "[INFO] Đã xử lý 10500/25962\n",
            "[INFO] Đã xử lý 11000/25962\n",
            "[INFO] Đã xử lý 11500/25962\n",
            "[INFO] Đã xử lý 12000/25962\n",
            "[INFO] Đã xử lý 12500/25962\n",
            "[INFO] Đã xử lý 13000/25962\n",
            "[INFO] Đã xử lý 13500/25962\n",
            "[INFO] Đã xử lý 14000/25962\n",
            "[INFO] Đã xử lý 14500/25962\n",
            "[INFO] Đã xử lý 15000/25962\n",
            "[INFO] Đã xử lý 15500/25962\n",
            "[INFO] Đã xử lý 16000/25962\n",
            "[INFO] Đã xử lý 16500/25962\n",
            "[INFO] Đã xử lý 17000/25962\n",
            "[INFO] Đã xử lý 17500/25962\n",
            "[INFO] Đã xử lý 18000/25962\n",
            "[INFO] Đã xử lý 18500/25962\n",
            "[INFO] Đã xử lý 19000/25962\n",
            "[INFO] Đã xử lý 19500/25962\n",
            "[INFO] Đã xử lý 20000/25962\n",
            "[INFO] Đã xử lý 20500/25962\n",
            "[INFO] Đã xử lý 21000/25962\n",
            "[INFO] Đã xử lý 21500/25962\n",
            "[INFO] Đã xử lý 22000/25962\n",
            "[INFO] Đã xử lý 22500/25962\n",
            "[INFO] Đã xử lý 23000/25962\n",
            "[INFO] Đã xử lý 23500/25962\n",
            "[INFO] Đã xử lý 24000/25962\n",
            "[INFO] Đã xử lý 24500/25962\n",
            "[INFO] Đã xử lý 25000/25962\n",
            "[INFO] Đã xử lý 25500/25962\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from keras.optimizers import Adam\n",
        "# Chia tách dữ liệu vào 02 tập, training: 75% và testing: 25%\n",
        "(trainX, testX, trainY, testY) = train_test_split(data, labels,test_size=0.25, random_state=42)\n",
        "# Chuyển dữ liệu nhãn ở số nguyên vào biểu diễn dưới dạng vectors\n",
        "trainY = LabelBinarizer().fit_transform(trainY)\n",
        "testY = LabelBinarizer().fit_transform(testY)\n",
        "\n",
        "# Khởi tạo danh sách các label cho tập dữ liệu flowers\n",
        "label_names = [\"cat\", \"dog\", \"panda\"]\n",
        "\n",
        "# Bước 2: Khởi tạo bộ tối ưu và model\n",
        "print(\"[INFO]: Biên dịch model....\")\n",
        "# Các tham số bộ tối ưu:\n",
        "#   - learning_rate: Tốc dộ học\n",
        "#   - decay: sử dụng để giảm từ từ tốc độ học theo thời gian\n",
        "#            được tính bằng Tốc độ học /tổng epoch. Dùng để tránh overfitting\n",
        "#            và tăng độ chính xác khi tranning\n",
        "#   - momentum: Hệ số quán tính\n",
        "#   - nesterov = True: sử dụng phương pháp tối ưu Nestrov accelerated gradient\n",
        "optimizer = SGD(learning_rate=0.01, momentum=0.9, nesterov=True)\n",
        "\n",
        "model =MiniVGGNet.build(width=32, height=32, depth=3, classes=3)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
        "\n",
        "# Bước 3: Train the network\n",
        "print(\"[INFO]: Đang trainning....\")\n",
        "H = model.fit(trainX, trainY, validation_data=(testX, testY), batch_size=64, epochs=50, verbose=1)\n",
        "\n",
        "\n",
        "model.summary() # Hiển thị tóm tắt các tham số của model\n",
        "\n",
        "# Bước 4: Đánh giá mạng\n",
        "print(\"[INFO]: Đánh giá model....\")\n",
        "predictions = model.predict(testX, batch_size=64)\n",
        "print(classification_report(testY.argmax(axis=1), predictions.argmax(axis=1), target_names=label_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "crZmW0Qw9bmz",
        "outputId": "64f5e695-a819-401c-d6f5-eb2dad115e0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO]: Biên dịch model....\n",
            "[INFO]: Đang trainning....\n",
            "Epoch 1/50\n",
            "305/305 [==============================] - 17s 16ms/step - loss: 0.9653 - accuracy: 0.5868 - val_loss: 1.2325 - val_accuracy: 0.4069\n",
            "Epoch 2/50\n",
            "305/305 [==============================] - 4s 12ms/step - loss: 0.7879 - accuracy: 0.6432 - val_loss: 0.9192 - val_accuracy: 0.6377\n",
            "Epoch 3/50\n",
            "305/305 [==============================] - 4s 12ms/step - loss: 0.7044 - accuracy: 0.6844 - val_loss: 0.6287 - val_accuracy: 0.6923\n",
            "Epoch 4/50\n",
            "305/305 [==============================] - 4s 12ms/step - loss: 0.6427 - accuracy: 0.7073 - val_loss: 0.8231 - val_accuracy: 0.6358\n",
            "Epoch 5/50\n",
            "305/305 [==============================] - 4s 12ms/step - loss: 0.5915 - accuracy: 0.7294 - val_loss: 0.5636 - val_accuracy: 0.7381\n",
            "Epoch 6/50\n",
            "305/305 [==============================] - 3s 11ms/step - loss: 0.5541 - accuracy: 0.7535 - val_loss: 0.5115 - val_accuracy: 0.7611\n",
            "Epoch 7/50\n",
            "305/305 [==============================] - 3s 11ms/step - loss: 0.5224 - accuracy: 0.7654 - val_loss: 0.7755 - val_accuracy: 0.6888\n",
            "Epoch 8/50\n",
            "305/305 [==============================] - 4s 14ms/step - loss: 0.4862 - accuracy: 0.7783 - val_loss: 0.4955 - val_accuracy: 0.7711\n",
            "Epoch 9/50\n",
            "305/305 [==============================] - 4s 12ms/step - loss: 0.4511 - accuracy: 0.7970 - val_loss: 0.4777 - val_accuracy: 0.7906\n",
            "Epoch 10/50\n",
            "305/305 [==============================] - 4s 12ms/step - loss: 0.4309 - accuracy: 0.8131 - val_loss: 0.4268 - val_accuracy: 0.8111\n",
            "Epoch 11/50\n",
            "305/305 [==============================] - 4s 12ms/step - loss: 0.3900 - accuracy: 0.8314 - val_loss: 0.5518 - val_accuracy: 0.7774\n",
            "Epoch 12/50\n",
            "305/305 [==============================] - 4s 13ms/step - loss: 0.3641 - accuracy: 0.8414 - val_loss: 0.5455 - val_accuracy: 0.7842\n",
            "Epoch 13/50\n",
            "305/305 [==============================] - 4s 12ms/step - loss: 0.3422 - accuracy: 0.8565 - val_loss: 0.4439 - val_accuracy: 0.8153\n",
            "Epoch 14/50\n",
            "305/305 [==============================] - 3s 11ms/step - loss: 0.3219 - accuracy: 0.8617 - val_loss: 0.5038 - val_accuracy: 0.7889\n",
            "Epoch 15/50\n",
            "305/305 [==============================] - 4s 13ms/step - loss: 0.3031 - accuracy: 0.8729 - val_loss: 0.3354 - val_accuracy: 0.8600\n",
            "Epoch 16/50\n",
            "305/305 [==============================] - 4s 12ms/step - loss: 0.2753 - accuracy: 0.8849 - val_loss: 0.3573 - val_accuracy: 0.8561\n",
            "Epoch 17/50\n",
            "305/305 [==============================] - 3s 11ms/step - loss: 0.2755 - accuracy: 0.8869 - val_loss: 0.4112 - val_accuracy: 0.8370\n",
            "Epoch 18/50\n",
            "305/305 [==============================] - 4s 12ms/step - loss: 0.2537 - accuracy: 0.8967 - val_loss: 0.5125 - val_accuracy: 0.8028\n",
            "Epoch 19/50\n",
            "305/305 [==============================] - 5s 17ms/step - loss: 0.2374 - accuracy: 0.9026 - val_loss: 0.3949 - val_accuracy: 0.8510\n",
            "Epoch 20/50\n",
            "305/305 [==============================] - 3s 11ms/step - loss: 0.2353 - accuracy: 0.9053 - val_loss: 0.6071 - val_accuracy: 0.7863\n",
            "Epoch 21/50\n",
            "305/305 [==============================] - 4s 12ms/step - loss: 0.2094 - accuracy: 0.9175 - val_loss: 0.6024 - val_accuracy: 0.7940\n",
            "Epoch 22/50\n",
            "305/305 [==============================] - 4s 12ms/step - loss: 0.2071 - accuracy: 0.9169 - val_loss: 0.4526 - val_accuracy: 0.8407\n",
            "Epoch 23/50\n",
            "305/305 [==============================] - 4s 14ms/step - loss: 0.1939 - accuracy: 0.9243 - val_loss: 0.4743 - val_accuracy: 0.8390\n",
            "Epoch 24/50\n",
            "305/305 [==============================] - 3s 11ms/step - loss: 0.1803 - accuracy: 0.9295 - val_loss: 0.4026 - val_accuracy: 0.8561\n",
            "Epoch 25/50\n",
            "305/305 [==============================] - 4s 12ms/step - loss: 0.1647 - accuracy: 0.9357 - val_loss: 0.3082 - val_accuracy: 0.8857\n",
            "Epoch 26/50\n",
            "305/305 [==============================] - 4s 13ms/step - loss: 0.1539 - accuracy: 0.9390 - val_loss: 0.4424 - val_accuracy: 0.8489\n",
            "Epoch 27/50\n",
            "305/305 [==============================] - 4s 12ms/step - loss: 0.1604 - accuracy: 0.9372 - val_loss: 0.3758 - val_accuracy: 0.8786\n",
            "Epoch 28/50\n",
            "305/305 [==============================] - 4s 12ms/step - loss: 0.1470 - accuracy: 0.9436 - val_loss: 0.4334 - val_accuracy: 0.8598\n",
            "Epoch 29/50\n",
            "305/305 [==============================] - 3s 11ms/step - loss: 0.1449 - accuracy: 0.9443 - val_loss: 0.3252 - val_accuracy: 0.8858\n",
            "Epoch 30/50\n",
            "305/305 [==============================] - 4s 13ms/step - loss: 0.1254 - accuracy: 0.9527 - val_loss: 0.3582 - val_accuracy: 0.8815\n",
            "Epoch 31/50\n",
            "305/305 [==============================] - 4s 12ms/step - loss: 0.1256 - accuracy: 0.9532 - val_loss: 0.5219 - val_accuracy: 0.8535\n",
            "Epoch 32/50\n",
            "305/305 [==============================] - 4s 12ms/step - loss: 0.1325 - accuracy: 0.9497 - val_loss: 0.3216 - val_accuracy: 0.8882\n",
            "Epoch 33/50\n",
            "305/305 [==============================] - 4s 12ms/step - loss: 0.1275 - accuracy: 0.9524 - val_loss: 0.3955 - val_accuracy: 0.8729\n",
            "Epoch 34/50\n",
            "305/305 [==============================] - 4s 13ms/step - loss: 0.1080 - accuracy: 0.9604 - val_loss: 0.4552 - val_accuracy: 0.8629\n",
            "Epoch 35/50\n",
            "305/305 [==============================] - 3s 11ms/step - loss: 0.1127 - accuracy: 0.9589 - val_loss: 0.3344 - val_accuracy: 0.8886\n",
            "Epoch 36/50\n",
            "305/305 [==============================] - 3s 11ms/step - loss: 0.1181 - accuracy: 0.9567 - val_loss: 0.4071 - val_accuracy: 0.8801\n",
            "Epoch 37/50\n",
            "305/305 [==============================] - 5s 16ms/step - loss: 0.0932 - accuracy: 0.9647 - val_loss: 0.3564 - val_accuracy: 0.8925\n",
            "Epoch 38/50\n",
            "305/305 [==============================] - 5s 16ms/step - loss: 0.1007 - accuracy: 0.9627 - val_loss: 0.3992 - val_accuracy: 0.8689\n",
            "Epoch 39/50\n",
            "305/305 [==============================] - 3s 11ms/step - loss: 0.0918 - accuracy: 0.9655 - val_loss: 0.3276 - val_accuracy: 0.8951\n",
            "Epoch 40/50\n",
            "305/305 [==============================] - 4s 12ms/step - loss: 0.1079 - accuracy: 0.9602 - val_loss: 0.3969 - val_accuracy: 0.8812\n",
            "Epoch 41/50\n",
            "305/305 [==============================] - 4s 14ms/step - loss: 0.0937 - accuracy: 0.9659 - val_loss: 0.3032 - val_accuracy: 0.9029\n",
            "Epoch 42/50\n",
            "305/305 [==============================] - 3s 11ms/step - loss: 0.0830 - accuracy: 0.9686 - val_loss: 0.3281 - val_accuracy: 0.8959\n",
            "Epoch 43/50\n",
            "305/305 [==============================] - 4s 12ms/step - loss: 0.0832 - accuracy: 0.9712 - val_loss: 0.3361 - val_accuracy: 0.8931\n",
            "Epoch 44/50\n",
            "305/305 [==============================] - 4s 12ms/step - loss: 0.0778 - accuracy: 0.9721 - val_loss: 0.3126 - val_accuracy: 0.8983\n",
            "Epoch 45/50\n",
            "305/305 [==============================] - 4s 14ms/step - loss: 0.0784 - accuracy: 0.9718 - val_loss: 0.3244 - val_accuracy: 0.8999\n",
            "Epoch 46/50\n",
            "305/305 [==============================] - 4s 11ms/step - loss: 0.0824 - accuracy: 0.9701 - val_loss: 0.3623 - val_accuracy: 0.8955\n",
            "Epoch 47/50\n",
            "305/305 [==============================] - 4s 13ms/step - loss: 0.0833 - accuracy: 0.9696 - val_loss: 0.4254 - val_accuracy: 0.8741\n",
            "Epoch 48/50\n",
            "305/305 [==============================] - 4s 13ms/step - loss: 0.0707 - accuracy: 0.9736 - val_loss: 0.4467 - val_accuracy: 0.8674\n",
            "Epoch 49/50\n",
            "305/305 [==============================] - 4s 13ms/step - loss: 0.0760 - accuracy: 0.9720 - val_loss: 0.3661 - val_accuracy: 0.8974\n",
            "Epoch 50/50\n",
            "305/305 [==============================] - 3s 11ms/step - loss: 0.0702 - accuracy: 0.9745 - val_loss: 0.3176 - val_accuracy: 0.9029\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " activation (Activation)     (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 32, 32, 32)       128       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 32, 32, 32)        9248      \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 32, 32, 32)       128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 16, 16, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 16, 16, 32)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 16, 16, 64)        18496     \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 16, 16, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 16, 16, 64)        36928     \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 16, 16, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 8, 8, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 4096)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               2097664   \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 512)               0         \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 512)              2048      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 3)                 1539      \n",
            "                                                                 \n",
            " activation_5 (Activation)   (None, 3)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,167,587\n",
            "Trainable params: 2,166,179\n",
            "Non-trainable params: 1,408\n",
            "_________________________________________________________________\n",
            "[INFO]: Đánh giá model....\n",
            "102/102 [==============================] - 0s 2ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         cat       0.91      0.85      0.88      2170\n",
            "         dog       0.83      0.92      0.88      2198\n",
            "       panda       0.99      0.94      0.96      2123\n",
            "\n",
            "    accuracy                           0.90      6491\n",
            "   macro avg       0.91      0.90      0.90      6491\n",
            "weighted avg       0.91      0.90      0.90      6491\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"modelver20.h5\")"
      ],
      "metadata": {
        "id": "2m6B3COY-TJV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from keras.optimizers import Adam\n",
        "# Chia tách dữ liệu vào 02 tập, training: 75% và testing: 25%\n",
        "(trainX, testX, trainY, testY) = train_test_split(data, labels,test_size=0.25, random_state=42)\n",
        "# Chuyển dữ liệu nhãn ở số nguyên vào biểu diễn dưới dạng vectors\n",
        "trainY = LabelBinarizer().fit_transform(trainY)\n",
        "testY = LabelBinarizer().fit_transform(testY)\n",
        "\n",
        "# Khởi tạo danh sách các label cho tập dữ liệu flowers\n",
        "label_names = [\"cat\", \"dog\", \"panda\"]\n",
        "\n",
        "# Bước 2: Khởi tạo bộ tối ưu và model\n",
        "print(\"[INFO]: Biên dịch model....\")\n",
        "# Các tham số bộ tối ưu:\n",
        "#   - learning_rate: Tốc dộ học\n",
        "#   - decay: sử dụng để giảm từ từ tốc độ học theo thời gian\n",
        "#            được tính bằng Tốc độ học /tổng epoch. Dùng để tránh overfitting\n",
        "#            và tăng độ chính xác khi tranning\n",
        "#   - momentum: Hệ số quán tính\n",
        "#   - nesterov = True: sử dụng phương pháp tối ưu Nestrov accelerated gradient\n",
        "optimizer = SGD(learning_rate=0.01, momentum=0.9, nesterov=True)\n",
        "\n",
        "input_shape = (32, 32, 3)\n",
        "num_classes = 3\n",
        "\n",
        "model = VGG16(input_shape,num_classes)\n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
        "\n",
        "# Bước 3: Train the network\n",
        "print(\"[INFO]: Đang trainning....\")\n",
        "H = model.fit(trainX, trainY, validation_data=(testX, testY), batch_size=64, epochs=50, verbose=1)\n",
        "\n",
        "\n",
        "model.summary() # Hiển thị tóm tắt các tham số của model\n",
        "\n",
        "# Bước 4: Đánh giá mạng\n",
        "print(\"[INFO]: Đánh giá model....\")\n",
        "predictions = model.predict(testX, batch_size=64)\n",
        "print(classification_report(testY.argmax(axis=1), predictions.argmax(axis=1), target_names=label_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ZKGfCUCJe9R",
        "outputId": "816f5f8b-eafb-4fbd-8d49-97666cd5c39a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO]: Biên dịch model....\n",
            "[INFO]: Đang trainning....\n",
            "Epoch 1/50\n",
            "305/305 [==============================] - 26s 44ms/step - loss: 1.0988 - accuracy: 0.3409 - val_loss: 1.0991 - val_accuracy: 0.3520\n",
            "Epoch 2/50\n",
            "305/305 [==============================] - 12s 38ms/step - loss: 1.0932 - accuracy: 0.3597 - val_loss: 1.0466 - val_accuracy: 0.4485\n",
            "Epoch 3/50\n",
            "305/305 [==============================] - 12s 39ms/step - loss: 0.9547 - accuracy: 0.4925 - val_loss: 0.8074 - val_accuracy: 0.5685\n",
            "Epoch 4/50\n",
            "305/305 [==============================] - 12s 39ms/step - loss: 0.7790 - accuracy: 0.5802 - val_loss: 0.8252 - val_accuracy: 0.5538\n",
            "Epoch 5/50\n",
            "305/305 [==============================] - 12s 40ms/step - loss: 0.6963 - accuracy: 0.6177 - val_loss: 0.6587 - val_accuracy: 0.6238\n",
            "Epoch 6/50\n",
            "305/305 [==============================] - 12s 39ms/step - loss: 0.6486 - accuracy: 0.6386 - val_loss: 0.6366 - val_accuracy: 0.6494\n",
            "Epoch 7/50\n",
            "305/305 [==============================] - 12s 40ms/step - loss: 0.6075 - accuracy: 0.6759 - val_loss: 0.6056 - val_accuracy: 0.6994\n",
            "Epoch 8/50\n",
            "305/305 [==============================] - 12s 41ms/step - loss: 0.5689 - accuracy: 0.7092 - val_loss: 0.5798 - val_accuracy: 0.7082\n",
            "Epoch 9/50\n",
            "305/305 [==============================] - 12s 40ms/step - loss: 0.5220 - accuracy: 0.7481 - val_loss: 0.5540 - val_accuracy: 0.7201\n",
            "Epoch 10/50\n",
            "305/305 [==============================] - 12s 40ms/step - loss: 0.4750 - accuracy: 0.7783 - val_loss: 0.5521 - val_accuracy: 0.7584\n",
            "Epoch 11/50\n",
            "305/305 [==============================] - 12s 40ms/step - loss: 0.4118 - accuracy: 0.8151 - val_loss: 0.5171 - val_accuracy: 0.7671\n",
            "Epoch 12/50\n",
            "305/305 [==============================] - 12s 40ms/step - loss: 0.3637 - accuracy: 0.8412 - val_loss: 0.6470 - val_accuracy: 0.7363\n",
            "Epoch 13/50\n",
            "305/305 [==============================] - 12s 40ms/step - loss: 0.3125 - accuracy: 0.8669 - val_loss: 0.5041 - val_accuracy: 0.8013\n",
            "Epoch 14/50\n",
            "305/305 [==============================] - 12s 40ms/step - loss: 0.2713 - accuracy: 0.8913 - val_loss: 0.6106 - val_accuracy: 0.7766\n",
            "Epoch 15/50\n",
            "305/305 [==============================] - 12s 40ms/step - loss: 0.2219 - accuracy: 0.9118 - val_loss: 0.4407 - val_accuracy: 0.8304\n",
            "Epoch 16/50\n",
            "305/305 [==============================] - 12s 40ms/step - loss: 0.1843 - accuracy: 0.9277 - val_loss: 0.6557 - val_accuracy: 0.7809\n",
            "Epoch 17/50\n",
            "305/305 [==============================] - 12s 39ms/step - loss: 0.1510 - accuracy: 0.9423 - val_loss: 0.8960 - val_accuracy: 0.7447\n",
            "Epoch 18/50\n",
            "305/305 [==============================] - 12s 39ms/step - loss: 0.1323 - accuracy: 0.9520 - val_loss: 0.5147 - val_accuracy: 0.8438\n",
            "Epoch 19/50\n",
            "305/305 [==============================] - 12s 39ms/step - loss: 0.1039 - accuracy: 0.9607 - val_loss: 0.4588 - val_accuracy: 0.8595\n",
            "Epoch 20/50\n",
            "305/305 [==============================] - 12s 40ms/step - loss: 0.0806 - accuracy: 0.9709 - val_loss: 0.4570 - val_accuracy: 0.8569\n",
            "Epoch 21/50\n",
            "305/305 [==============================] - 12s 39ms/step - loss: 0.0742 - accuracy: 0.9741 - val_loss: 0.5054 - val_accuracy: 0.8473\n",
            "Epoch 22/50\n",
            "305/305 [==============================] - 12s 40ms/step - loss: 0.0636 - accuracy: 0.9778 - val_loss: 0.4223 - val_accuracy: 0.8677\n",
            "Epoch 23/50\n",
            "305/305 [==============================] - 12s 40ms/step - loss: 0.0509 - accuracy: 0.9827 - val_loss: 0.4966 - val_accuracy: 0.8700\n",
            "Epoch 24/50\n",
            "305/305 [==============================] - 12s 40ms/step - loss: 0.0493 - accuracy: 0.9820 - val_loss: 0.5375 - val_accuracy: 0.8560\n",
            "Epoch 25/50\n",
            "305/305 [==============================] - 12s 40ms/step - loss: 0.0489 - accuracy: 0.9821 - val_loss: 0.4300 - val_accuracy: 0.8829\n",
            "Epoch 26/50\n",
            "305/305 [==============================] - 12s 40ms/step - loss: 0.0422 - accuracy: 0.9844 - val_loss: 0.4080 - val_accuracy: 0.8855\n",
            "Epoch 27/50\n",
            "305/305 [==============================] - 12s 41ms/step - loss: 0.0318 - accuracy: 0.9888 - val_loss: 0.4261 - val_accuracy: 0.8772\n",
            "Epoch 28/50\n",
            "305/305 [==============================] - 12s 40ms/step - loss: 0.0251 - accuracy: 0.9916 - val_loss: 0.4669 - val_accuracy: 0.8898\n",
            "Epoch 29/50\n",
            "305/305 [==============================] - 12s 40ms/step - loss: 0.0253 - accuracy: 0.9912 - val_loss: 0.4735 - val_accuracy: 0.8883\n",
            "Epoch 30/50\n",
            "305/305 [==============================] - 12s 41ms/step - loss: 0.0238 - accuracy: 0.9920 - val_loss: 0.5139 - val_accuracy: 0.8855\n",
            "Epoch 31/50\n",
            "305/305 [==============================] - 12s 40ms/step - loss: 0.0249 - accuracy: 0.9915 - val_loss: 0.5185 - val_accuracy: 0.8766\n",
            "Epoch 32/50\n",
            "305/305 [==============================] - 12s 41ms/step - loss: 0.0240 - accuracy: 0.9916 - val_loss: 0.5002 - val_accuracy: 0.8771\n",
            "Epoch 33/50\n",
            "305/305 [==============================] - 12s 40ms/step - loss: 0.0217 - accuracy: 0.9931 - val_loss: 0.4204 - val_accuracy: 0.8920\n",
            "Epoch 34/50\n",
            "305/305 [==============================] - 12s 40ms/step - loss: 0.0200 - accuracy: 0.9939 - val_loss: 0.4522 - val_accuracy: 0.8855\n",
            "Epoch 35/50\n",
            "305/305 [==============================] - 12s 40ms/step - loss: 0.0155 - accuracy: 0.9941 - val_loss: 0.4684 - val_accuracy: 0.8954\n",
            "Epoch 36/50\n",
            "305/305 [==============================] - 12s 41ms/step - loss: 0.0147 - accuracy: 0.9952 - val_loss: 0.5340 - val_accuracy: 0.8932\n",
            "Epoch 37/50\n",
            "305/305 [==============================] - 12s 40ms/step - loss: 0.0181 - accuracy: 0.9932 - val_loss: 0.5196 - val_accuracy: 0.8837\n",
            "Epoch 38/50\n",
            "305/305 [==============================] - 12s 40ms/step - loss: 0.0174 - accuracy: 0.9941 - val_loss: 0.5235 - val_accuracy: 0.8922\n",
            "Epoch 39/50\n",
            "305/305 [==============================] - 12s 40ms/step - loss: 0.0158 - accuracy: 0.9946 - val_loss: 0.5539 - val_accuracy: 0.8788\n",
            "Epoch 40/50\n",
            "305/305 [==============================] - 12s 41ms/step - loss: 0.0158 - accuracy: 0.9944 - val_loss: 0.5215 - val_accuracy: 0.8848\n",
            "Epoch 41/50\n",
            "305/305 [==============================] - 12s 41ms/step - loss: 0.0103 - accuracy: 0.9968 - val_loss: 0.5064 - val_accuracy: 0.8931\n",
            "Epoch 42/50\n",
            "305/305 [==============================] - 12s 40ms/step - loss: 0.0096 - accuracy: 0.9966 - val_loss: 0.6320 - val_accuracy: 0.8629\n",
            "Epoch 43/50\n",
            "305/305 [==============================] - 12s 39ms/step - loss: 0.0152 - accuracy: 0.9946 - val_loss: 0.5623 - val_accuracy: 0.8800\n",
            "Epoch 44/50\n",
            "305/305 [==============================] - 12s 40ms/step - loss: 0.0126 - accuracy: 0.9954 - val_loss: 0.5016 - val_accuracy: 0.8838\n",
            "Epoch 45/50\n",
            "305/305 [==============================] - 12s 40ms/step - loss: 0.0035 - accuracy: 0.9990 - val_loss: 0.6159 - val_accuracy: 0.8931\n",
            "Epoch 46/50\n",
            "305/305 [==============================] - 12s 39ms/step - loss: 0.0154 - accuracy: 0.9948 - val_loss: 0.4889 - val_accuracy: 0.8931\n",
            "Epoch 47/50\n",
            "305/305 [==============================] - 12s 40ms/step - loss: 0.0081 - accuracy: 0.9975 - val_loss: 0.5596 - val_accuracy: 0.8845\n",
            "Epoch 48/50\n",
            "305/305 [==============================] - 12s 39ms/step - loss: 0.0087 - accuracy: 0.9970 - val_loss: 0.4902 - val_accuracy: 0.8992\n",
            "Epoch 49/50\n",
            "305/305 [==============================] - 12s 40ms/step - loss: 0.0129 - accuracy: 0.9959 - val_loss: 0.5564 - val_accuracy: 0.8689\n",
            "Epoch 50/50\n",
            "305/305 [==============================] - 12s 40ms/step - loss: 0.0082 - accuracy: 0.9974 - val_loss: 0.5574 - val_accuracy: 0.8969\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " activation (Activation)     (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 32, 32, 32)        9248      \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 16, 16, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 16, 16, 128)       36992     \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 16, 16, 128)       147584    \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 8, 8, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 8, 8, 256)         295168    \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 8, 8, 256)         0         \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 8, 8, 256)         590080    \n",
            "                                                                 \n",
            " activation_5 (Activation)   (None, 8, 8, 256)         0         \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 8, 8, 256)         590080    \n",
            "                                                                 \n",
            " activation_6 (Activation)   (None, 8, 8, 256)         0         \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 4, 4, 256)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 4, 4, 512)         1180160   \n",
            "                                                                 \n",
            " activation_7 (Activation)   (None, 4, 4, 512)         0         \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 4, 4, 512)         2359808   \n",
            "                                                                 \n",
            " activation_8 (Activation)   (None, 4, 4, 512)         0         \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 4, 4, 512)         2359808   \n",
            "                                                                 \n",
            " activation_9 (Activation)   (None, 4, 4, 512)         0         \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 2, 2, 512)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 2, 2, 512)         2359808   \n",
            "                                                                 \n",
            " activation_10 (Activation)  (None, 2, 2, 512)         0         \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 2, 2, 512)         2359808   \n",
            "                                                                 \n",
            " activation_11 (Activation)  (None, 2, 2, 512)         0         \n",
            "                                                                 \n",
            " conv2d_12 (Conv2D)          (None, 2, 2, 512)         2359808   \n",
            "                                                                 \n",
            " activation_12 (Activation)  (None, 2, 2, 512)         0         \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 1, 1, 512)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 512)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 4096)              2101248   \n",
            "                                                                 \n",
            " activation_13 (Activation)  (None, 4096)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 4096)              16781312  \n",
            "                                                                 \n",
            " activation_14 (Activation)  (None, 4096)              0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 3)                 12291     \n",
            "                                                                 \n",
            " activation_15 (Activation)  (None, 3)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 33,544,099\n",
            "Trainable params: 33,544,099\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "[INFO]: Đánh giá model....\n",
            "102/102 [==============================] - 1s 10ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         cat       0.84      0.90      0.87      2170\n",
            "         dog       0.87      0.84      0.86      2198\n",
            "       panda       0.99      0.95      0.97      2123\n",
            "\n",
            "    accuracy                           0.90      6491\n",
            "   macro avg       0.90      0.90      0.90      6491\n",
            "weighted avg       0.90      0.90      0.90      6491\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.layers.core import Activation\n",
        "from keras.layers.core import Flatten\n",
        "from keras.layers.core import Dropout\n",
        "from keras.layers.core import Dense\n",
        "from keras import backend as K\n",
        "\n",
        "class MiniVGGNets:\n",
        "    @staticmethod\n",
        "    def build(width, height, depth, classes):\n",
        "        # Khởi tạo mô hình, shape ảnh đầu vào và số kênh của ảnh đầu vào\n",
        "        model = Sequential()\n",
        "        input_shape = (height, width, depth)\n",
        "        channel_dim = -1  # chỉ số của số kênh ảnh đầu vào\n",
        "                          # giá trị -1 ý muốn nói chỉ số kênh nằm cuối cùng\n",
        "                          # của danh sách chứa dữ liệu ảnh đầu vào\n",
        "\n",
        "        # sử dụng 'channels_first' để cập nhật shape và số kênh ảnh đầu vào\n",
        "        if K.image_data_format() == 'channels_first':\n",
        "            input_shape = (depth, height, width)\n",
        "            channel_dim = 1\n",
        "\n",
        "        # Chuỗi layer đầu tiên  CONV => RELU => CONV => RELU => POOL\n",
        "        model.add(Conv2D(32, (3, 3), padding='same', input_shape=input_shape))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization(axis=channel_dim))\n",
        "        model.add(Conv2D(32, (3, 3), padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization(axis=channel_dim))\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "        model.add(Dropout(0.25))\n",
        "\n",
        "        # Chuỗi layer thứ hai CONV => RELU => CONV => RELU => POOL\n",
        "        model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization(axis=channel_dim))\n",
        "        model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization(axis=channel_dim))\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "        model.add(Dropout(0.25))\n",
        "\n",
        "        # Chuỗi layer thứ ba CONV => RELU => CONV => RELU => POOL\n",
        "        model.add(Conv2D(128, (3, 3), padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization(axis=channel_dim))\n",
        "        model.add(Conv2D(128, (3, 3), padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization(axis=channel_dim))\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "        model.add(Dropout(0.25))\n",
        "\n",
        "        # Thiết lập FC thứ nhất => RELU layers\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(1024))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(0.25))   # Dropout 50%\n",
        "\n",
        "        # THiết lập FC thứ hai => Hàm phân lớp Softmax\n",
        "        model.add(Dense(classes))\n",
        "        model.add(Activation('softmax'))\n",
        "\n",
        "        # Trả về kiến trúc mạng/mô hình\n",
        "        return model\n"
      ],
      "metadata": {
        "id": "UU344l6H7hfw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from keras.optimizers import Adam\n",
        "# Chia tách dữ liệu vào 02 tập, training: 75% và testing: 25%\n",
        "(trainX, testX, trainY, testY) = train_test_split(data, labels,test_size=0.25, random_state=42)\n",
        "# Chuyển dữ liệu nhãn ở số nguyên vào biểu diễn dưới dạng vectors\n",
        "trainY = LabelBinarizer().fit_transform(trainY)\n",
        "testY = LabelBinarizer().fit_transform(testY)\n",
        "\n",
        "# Khởi tạo danh sách các label cho tập dữ liệu flowers\n",
        "label_names = [\"cat\", \"dog\", \"panda\"]\n",
        "\n",
        "# Bước 2: Khởi tạo bộ tối ưu và model\n",
        "print(\"[INFO]: Biên dịch model....\")\n",
        "# Các tham số bộ tối ưu:\n",
        "#   - learning_rate: Tốc dộ học\n",
        "#   - decay: sử dụng để giảm từ từ tốc độ học theo thời gian\n",
        "#            được tính bằng Tốc độ học /tổng epoch. Dùng để tránh overfitting\n",
        "#            và tăng độ chính xác khi tranning\n",
        "#   - momentum: Hệ số quán tính\n",
        "#   - nesterov = True: sử dụng phương pháp tối ưu Nestrov accelerated gradient\n",
        "optimizer = SGD(learning_rate=0.01, momentum=0.9, nesterov=True)\n",
        "\n",
        "model =MiniVGGNets.build(width=32, height=32, depth=3, classes=3)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
        "\n",
        "# Bước 3: Train the network\n",
        "print(\"[INFO]: Đang trainning....\")\n",
        "H = model.fit(trainX, trainY, validation_data=(testX, testY), batch_size=64, epochs=50, verbose=1)\n",
        "\n",
        "\n",
        "model.summary() # Hiển thị tóm tắt các tham số của model\n",
        "\n",
        "# Bước 4: Đánh giá mạng\n",
        "print(\"[INFO]: Đánh giá model....\")\n",
        "predictions = model.predict(testX, batch_size=64)\n",
        "print(classification_report(testY.argmax(axis=1), predictions.argmax(axis=1), target_names=label_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2gQbMyp87kxE",
        "outputId": "55fbc7d4-e27d-4ad6-e72f-09d013e5b134"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO]: Biên dịch model....\n",
            "[INFO]: Đang trainning....\n",
            "Epoch 1/50\n",
            "305/305 [==============================] - 20s 17ms/step - loss: 0.9642 - accuracy: 0.5987 - val_loss: 1.2091 - val_accuracy: 0.4981\n",
            "Epoch 2/50\n",
            "305/305 [==============================] - 5s 16ms/step - loss: 0.7199 - accuracy: 0.6772 - val_loss: 0.8159 - val_accuracy: 0.6320\n",
            "Epoch 3/50\n",
            "305/305 [==============================] - 5s 17ms/step - loss: 0.6525 - accuracy: 0.7037 - val_loss: 1.0113 - val_accuracy: 0.6427\n",
            "Epoch 4/50\n",
            "305/305 [==============================] - 5s 15ms/step - loss: 0.5900 - accuracy: 0.7329 - val_loss: 0.8130 - val_accuracy: 0.6777\n",
            "Epoch 5/50\n",
            "305/305 [==============================] - 5s 16ms/step - loss: 0.5459 - accuracy: 0.7502 - val_loss: 0.5042 - val_accuracy: 0.7652\n",
            "Epoch 6/50\n",
            "305/305 [==============================] - 5s 16ms/step - loss: 0.5036 - accuracy: 0.7734 - val_loss: 0.5488 - val_accuracy: 0.7618\n",
            "Epoch 7/50\n",
            "305/305 [==============================] - 4s 14ms/step - loss: 0.4576 - accuracy: 0.7999 - val_loss: 0.6000 - val_accuracy: 0.7421\n",
            "Epoch 8/50\n",
            "305/305 [==============================] - 5s 17ms/step - loss: 0.4399 - accuracy: 0.8077 - val_loss: 0.5571 - val_accuracy: 0.7777\n",
            "Epoch 9/50\n",
            "305/305 [==============================] - 5s 16ms/step - loss: 0.4087 - accuracy: 0.8236 - val_loss: 0.3901 - val_accuracy: 0.8339\n",
            "Epoch 10/50\n",
            "305/305 [==============================] - 5s 15ms/step - loss: 0.3748 - accuracy: 0.8402 - val_loss: 0.6624 - val_accuracy: 0.7367\n",
            "Epoch 11/50\n",
            "305/305 [==============================] - 5s 16ms/step - loss: 0.3543 - accuracy: 0.8479 - val_loss: 0.3704 - val_accuracy: 0.8426\n",
            "Epoch 12/50\n",
            "305/305 [==============================] - 5s 16ms/step - loss: 0.3378 - accuracy: 0.8585 - val_loss: 0.4576 - val_accuracy: 0.8182\n",
            "Epoch 13/50\n",
            "305/305 [==============================] - 4s 14ms/step - loss: 0.3045 - accuracy: 0.8747 - val_loss: 0.4422 - val_accuracy: 0.8307\n",
            "Epoch 14/50\n",
            "305/305 [==============================] - 5s 17ms/step - loss: 0.2868 - accuracy: 0.8823 - val_loss: 0.4041 - val_accuracy: 0.8422\n",
            "Epoch 15/50\n",
            "305/305 [==============================] - 5s 16ms/step - loss: 0.2657 - accuracy: 0.8908 - val_loss: 0.4870 - val_accuracy: 0.8156\n",
            "Epoch 16/50\n",
            "305/305 [==============================] - 4s 15ms/step - loss: 0.2428 - accuracy: 0.9041 - val_loss: 0.4895 - val_accuracy: 0.8188\n",
            "Epoch 17/50\n",
            "305/305 [==============================] - 5s 17ms/step - loss: 0.2296 - accuracy: 0.9080 - val_loss: 0.3540 - val_accuracy: 0.8646\n",
            "Epoch 18/50\n",
            "305/305 [==============================] - 5s 17ms/step - loss: 0.2193 - accuracy: 0.9107 - val_loss: 0.4861 - val_accuracy: 0.8313\n",
            "Epoch 19/50\n",
            "305/305 [==============================] - 5s 16ms/step - loss: 0.2040 - accuracy: 0.9180 - val_loss: 0.3357 - val_accuracy: 0.8757\n",
            "Epoch 20/50\n",
            "305/305 [==============================] - 5s 17ms/step - loss: 0.1899 - accuracy: 0.9236 - val_loss: 0.3531 - val_accuracy: 0.8686\n",
            "Epoch 21/50\n",
            "305/305 [==============================] - 5s 15ms/step - loss: 0.1829 - accuracy: 0.9306 - val_loss: 0.3118 - val_accuracy: 0.8946\n",
            "Epoch 22/50\n",
            "305/305 [==============================] - 5s 15ms/step - loss: 0.1736 - accuracy: 0.9321 - val_loss: 0.4588 - val_accuracy: 0.8483\n",
            "Epoch 23/50\n",
            "305/305 [==============================] - 5s 18ms/step - loss: 0.1595 - accuracy: 0.9389 - val_loss: 0.3366 - val_accuracy: 0.8843\n",
            "Epoch 24/50\n",
            "305/305 [==============================] - 5s 16ms/step - loss: 0.1468 - accuracy: 0.9438 - val_loss: 0.2634 - val_accuracy: 0.9046\n",
            "Epoch 25/50\n",
            "305/305 [==============================] - 4s 14ms/step - loss: 0.1362 - accuracy: 0.9466 - val_loss: 0.2954 - val_accuracy: 0.8972\n",
            "Epoch 26/50\n",
            "305/305 [==============================] - 5s 17ms/step - loss: 0.1346 - accuracy: 0.9496 - val_loss: 0.4397 - val_accuracy: 0.8623\n",
            "Epoch 27/50\n",
            "305/305 [==============================] - 5s 16ms/step - loss: 0.1379 - accuracy: 0.9478 - val_loss: 0.2569 - val_accuracy: 0.9110\n",
            "Epoch 28/50\n",
            "305/305 [==============================] - 4s 15ms/step - loss: 0.1239 - accuracy: 0.9541 - val_loss: 0.5240 - val_accuracy: 0.8435\n",
            "Epoch 29/50\n",
            "305/305 [==============================] - 5s 18ms/step - loss: 0.1174 - accuracy: 0.9562 - val_loss: 0.3189 - val_accuracy: 0.9031\n",
            "Epoch 30/50\n",
            "305/305 [==============================] - 5s 15ms/step - loss: 0.1149 - accuracy: 0.9580 - val_loss: 0.2917 - val_accuracy: 0.9056\n",
            "Epoch 31/50\n",
            "305/305 [==============================] - 4s 15ms/step - loss: 0.0931 - accuracy: 0.9641 - val_loss: 0.3770 - val_accuracy: 0.8882\n",
            "Epoch 32/50\n",
            "305/305 [==============================] - 5s 18ms/step - loss: 0.0888 - accuracy: 0.9671 - val_loss: 0.4464 - val_accuracy: 0.8686\n",
            "Epoch 33/50\n",
            "305/305 [==============================] - 4s 15ms/step - loss: 0.0907 - accuracy: 0.9662 - val_loss: 0.2832 - val_accuracy: 0.9130\n",
            "Epoch 34/50\n",
            "305/305 [==============================] - 5s 15ms/step - loss: 0.0888 - accuracy: 0.9678 - val_loss: 0.3112 - val_accuracy: 0.9053\n",
            "Epoch 35/50\n",
            "305/305 [==============================] - 6s 18ms/step - loss: 0.0851 - accuracy: 0.9681 - val_loss: 0.2547 - val_accuracy: 0.9233\n",
            "Epoch 36/50\n",
            "305/305 [==============================] - 4s 15ms/step - loss: 0.0829 - accuracy: 0.9695 - val_loss: 0.2934 - val_accuracy: 0.9074\n",
            "Epoch 37/50\n",
            "305/305 [==============================] - 5s 15ms/step - loss: 0.0780 - accuracy: 0.9705 - val_loss: 1.2154 - val_accuracy: 0.7259\n",
            "Epoch 38/50\n",
            "305/305 [==============================] - 5s 16ms/step - loss: 0.0942 - accuracy: 0.9658 - val_loss: 0.3220 - val_accuracy: 0.9036\n",
            "Epoch 39/50\n",
            "305/305 [==============================] - 5s 15ms/step - loss: 0.0829 - accuracy: 0.9696 - val_loss: 0.3078 - val_accuracy: 0.9102\n",
            "Epoch 40/50\n",
            "305/305 [==============================] - 5s 16ms/step - loss: 0.0795 - accuracy: 0.9717 - val_loss: 0.3309 - val_accuracy: 0.9063\n",
            "Epoch 41/50\n",
            "305/305 [==============================] - 6s 19ms/step - loss: 0.0698 - accuracy: 0.9738 - val_loss: 0.2790 - val_accuracy: 0.9162\n",
            "Epoch 42/50\n",
            "305/305 [==============================] - 5s 15ms/step - loss: 0.0643 - accuracy: 0.9750 - val_loss: 0.4148 - val_accuracy: 0.8882\n",
            "Epoch 43/50\n",
            "305/305 [==============================] - 5s 16ms/step - loss: 0.0689 - accuracy: 0.9743 - val_loss: 0.2816 - val_accuracy: 0.9197\n",
            "Epoch 44/50\n",
            "305/305 [==============================] - 5s 17ms/step - loss: 0.0670 - accuracy: 0.9761 - val_loss: 0.2776 - val_accuracy: 0.9210\n",
            "Epoch 45/50\n",
            "305/305 [==============================] - 5s 15ms/step - loss: 0.0569 - accuracy: 0.9788 - val_loss: 0.3208 - val_accuracy: 0.9120\n",
            "Epoch 46/50\n",
            "305/305 [==============================] - 5s 16ms/step - loss: 0.0612 - accuracy: 0.9786 - val_loss: 0.3066 - val_accuracy: 0.9185\n",
            "Epoch 47/50\n",
            "305/305 [==============================] - 5s 17ms/step - loss: 0.0574 - accuracy: 0.9793 - val_loss: 0.3266 - val_accuracy: 0.9106\n",
            "Epoch 48/50\n",
            "305/305 [==============================] - 4s 15ms/step - loss: 0.0612 - accuracy: 0.9782 - val_loss: 0.3063 - val_accuracy: 0.9119\n",
            "Epoch 49/50\n",
            "305/305 [==============================] - 5s 16ms/step - loss: 0.0525 - accuracy: 0.9805 - val_loss: 0.2821 - val_accuracy: 0.9177\n",
            "Epoch 50/50\n",
            "305/305 [==============================] - 4s 15ms/step - loss: 0.0503 - accuracy: 0.9808 - val_loss: 0.2517 - val_accuracy: 0.9276\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " activation (Activation)     (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 32, 32, 32)       128       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 32, 32, 32)        9248      \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 32, 32, 32)       128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 16, 16, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 16, 16, 32)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 16, 16, 64)        18496     \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 16, 16, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 16, 16, 64)        36928     \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 16, 16, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 8, 8, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 8, 8, 128)         73856     \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 8, 8, 128)        512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 8, 8, 128)         147584    \n",
            "                                                                 \n",
            " activation_5 (Activation)   (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 8, 8, 128)        512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 4, 4, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 4, 4, 128)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2048)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1024)              2098176   \n",
            "                                                                 \n",
            " activation_6 (Activation)   (None, 1024)              0         \n",
            "                                                                 \n",
            " batch_normalization_6 (Batc  (None, 1024)             4096      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 3)                 3075      \n",
            "                                                                 \n",
            " activation_7 (Activation)   (None, 3)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,394,147\n",
            "Trainable params: 2,391,203\n",
            "Non-trainable params: 2,944\n",
            "_________________________________________________________________\n",
            "[INFO]: Đánh giá model....\n",
            "102/102 [==============================] - 1s 4ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         cat       0.90      0.92      0.91      2170\n",
            "         dog       0.91      0.89      0.90      2198\n",
            "       panda       0.98      0.97      0.97      2123\n",
            "\n",
            "    accuracy                           0.93      6491\n",
            "   macro avg       0.93      0.93      0.93      6491\n",
            "weighted avg       0.93      0.93      0.93      6491\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from keras.optimizers import Adam\n",
        "# Chia tách dữ liệu vào 02 tập, training: 75% và testing: 25%\n",
        "(trainX, testX, trainY, testY) = train_test_split(data, labels,test_size=0.25, random_state=42)\n",
        "# Chuyển dữ liệu nhãn ở số nguyên vào biểu diễn dưới dạng vectors\n",
        "trainY = LabelBinarizer().fit_transform(trainY)\n",
        "testY = LabelBinarizer().fit_transform(testY)\n",
        "\n",
        "# Khởi tạo danh sách các label cho tập dữ liệu flowers\n",
        "label_names = [\"cat\", \"dog\", \"panda\"]\n",
        "\n",
        "# Bước 2: Khởi tạo bộ tối ưu và model\n",
        "print(\"[INFO]: Biên dịch model....\")\n",
        "# Các tham số bộ tối ưu:\n",
        "#   - learning_rate: Tốc dộ học\n",
        "#   - decay: sử dụng để giảm từ từ tốc độ học theo thời gian\n",
        "#            được tính bằng Tốc độ học /tổng epoch. Dùng để tránh overfitting\n",
        "#            và tăng độ chính xác khi tranning\n",
        "#   - momentum: Hệ số quán tính\n",
        "#   - nesterov = True: sử dụng phương pháp tối ưu Nestrov accelerated gradient\n",
        "optimizer = SGD(learning_rate=0.01, momentum=0.9, nesterov=True)\n",
        "\n",
        "model =MiniVGGNets.build(width=32, height=32, depth=3, classes=3)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
        "\n",
        "# Bước 3: Train the network\n",
        "print(\"[INFO]: Đang trainning....\")\n",
        "H = model.fit(trainX, trainY, validation_data=(testX, testY), batch_size=64, epochs=60, verbose=1)\n",
        "\n",
        "\n",
        "model.summary() # Hiển thị tóm tắt các tham số của model\n",
        "\n",
        "# Bước 4: Đánh giá mạng\n",
        "print(\"[INFO]: Đánh giá model....\")\n",
        "predictions = model.predict(testX, batch_size=64)\n",
        "print(classification_report(testY.argmax(axis=1), predictions.argmax(axis=1), target_names=label_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "szSpbhXS9Hpw",
        "outputId": "0c8dfbdc-b022-43d7-c3f9-3e11f1c0884e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO]: Biên dịch model....\n",
            "[INFO]: Đang trainning....\n",
            "Epoch 1/60\n",
            "305/305 [==============================] - 8s 17ms/step - loss: 0.9233 - accuracy: 0.6107 - val_loss: 1.1453 - val_accuracy: 0.5223\n",
            "Epoch 2/60\n",
            "305/305 [==============================] - 5s 17ms/step - loss: 0.7307 - accuracy: 0.6700 - val_loss: 1.8330 - val_accuracy: 0.4229\n",
            "Epoch 3/60\n",
            "305/305 [==============================] - 4s 15ms/step - loss: 0.6413 - accuracy: 0.7093 - val_loss: 0.8076 - val_accuracy: 0.6366\n",
            "Epoch 4/60\n",
            "305/305 [==============================] - 4s 15ms/step - loss: 0.5955 - accuracy: 0.7322 - val_loss: 0.6470 - val_accuracy: 0.7233\n",
            "Epoch 5/60\n",
            "305/305 [==============================] - 5s 17ms/step - loss: 0.5363 - accuracy: 0.7604 - val_loss: 0.5951 - val_accuracy: 0.7366\n",
            "Epoch 6/60\n",
            "305/305 [==============================] - 4s 15ms/step - loss: 0.5092 - accuracy: 0.7745 - val_loss: 0.8896 - val_accuracy: 0.6515\n",
            "Epoch 7/60\n",
            "305/305 [==============================] - 4s 15ms/step - loss: 0.4616 - accuracy: 0.7966 - val_loss: 0.6824 - val_accuracy: 0.7181\n",
            "Epoch 8/60\n",
            "305/305 [==============================] - 5s 18ms/step - loss: 0.4323 - accuracy: 0.8139 - val_loss: 0.4992 - val_accuracy: 0.7778\n",
            "Epoch 9/60\n",
            "305/305 [==============================] - 4s 15ms/step - loss: 0.3868 - accuracy: 0.8372 - val_loss: 0.5391 - val_accuracy: 0.7882\n",
            "Epoch 10/60\n",
            "305/305 [==============================] - 4s 15ms/step - loss: 0.3637 - accuracy: 0.8457 - val_loss: 0.5157 - val_accuracy: 0.7837\n",
            "Epoch 11/60\n",
            "305/305 [==============================] - 5s 16ms/step - loss: 0.3452 - accuracy: 0.8557 - val_loss: 0.4387 - val_accuracy: 0.8187\n",
            "Epoch 12/60\n",
            "305/305 [==============================] - 4s 14ms/step - loss: 0.3075 - accuracy: 0.8691 - val_loss: 0.4010 - val_accuracy: 0.8442\n",
            "Epoch 13/60\n",
            "305/305 [==============================] - 5s 15ms/step - loss: 0.2922 - accuracy: 0.8807 - val_loss: 0.3908 - val_accuracy: 0.8435\n",
            "Epoch 14/60\n",
            "305/305 [==============================] - 5s 18ms/step - loss: 0.2751 - accuracy: 0.8866 - val_loss: 0.3929 - val_accuracy: 0.8487\n",
            "Epoch 15/60\n",
            "305/305 [==============================] - 4s 15ms/step - loss: 0.2589 - accuracy: 0.8929 - val_loss: 0.4380 - val_accuracy: 0.8453\n",
            "Epoch 16/60\n",
            "305/305 [==============================] - 5s 15ms/step - loss: 0.2420 - accuracy: 0.9012 - val_loss: 0.3566 - val_accuracy: 0.8615\n",
            "Epoch 17/60\n",
            "305/305 [==============================] - 5s 18ms/step - loss: 0.2207 - accuracy: 0.9126 - val_loss: 0.3382 - val_accuracy: 0.8675\n",
            "Epoch 18/60\n",
            "305/305 [==============================] - 5s 15ms/step - loss: 0.2027 - accuracy: 0.9198 - val_loss: 0.3631 - val_accuracy: 0.8695\n",
            "Epoch 19/60\n",
            "305/305 [==============================] - 5s 15ms/step - loss: 0.1989 - accuracy: 0.9221 - val_loss: 0.3791 - val_accuracy: 0.8661\n",
            "Epoch 20/60\n",
            "305/305 [==============================] - 5s 17ms/step - loss: 0.1736 - accuracy: 0.9320 - val_loss: 0.3854 - val_accuracy: 0.8654\n",
            "Epoch 21/60\n",
            "305/305 [==============================] - 5s 15ms/step - loss: 0.1711 - accuracy: 0.9332 - val_loss: 0.3380 - val_accuracy: 0.8852\n",
            "Epoch 22/60\n",
            "305/305 [==============================] - 4s 14ms/step - loss: 0.1644 - accuracy: 0.9368 - val_loss: 0.2559 - val_accuracy: 0.9126\n",
            "Epoch 23/60\n",
            "305/305 [==============================] - 5s 15ms/step - loss: 0.1410 - accuracy: 0.9469 - val_loss: 0.4079 - val_accuracy: 0.8792\n",
            "Epoch 24/60\n",
            "305/305 [==============================] - 4s 14ms/step - loss: 0.1530 - accuracy: 0.9397 - val_loss: 0.3210 - val_accuracy: 0.8952\n",
            "Epoch 25/60\n",
            "305/305 [==============================] - 5s 15ms/step - loss: 0.1433 - accuracy: 0.9456 - val_loss: 0.2799 - val_accuracy: 0.9022\n",
            "Epoch 26/60\n",
            "305/305 [==============================] - 5s 17ms/step - loss: 0.1215 - accuracy: 0.9538 - val_loss: 0.3297 - val_accuracy: 0.8925\n",
            "Epoch 27/60\n",
            "305/305 [==============================] - 4s 15ms/step - loss: 0.1178 - accuracy: 0.9564 - val_loss: 0.2608 - val_accuracy: 0.9086\n",
            "Epoch 28/60\n",
            "305/305 [==============================] - 5s 15ms/step - loss: 0.1213 - accuracy: 0.9551 - val_loss: 0.2662 - val_accuracy: 0.9133\n",
            "Epoch 29/60\n",
            "305/305 [==============================] - 6s 18ms/step - loss: 0.1100 - accuracy: 0.9599 - val_loss: 0.4995 - val_accuracy: 0.8576\n",
            "Epoch 30/60\n",
            "305/305 [==============================] - 5s 15ms/step - loss: 0.1051 - accuracy: 0.9595 - val_loss: 0.2653 - val_accuracy: 0.9157\n",
            "Epoch 31/60\n",
            "305/305 [==============================] - 5s 15ms/step - loss: 0.1016 - accuracy: 0.9620 - val_loss: 0.2723 - val_accuracy: 0.9145\n",
            "Epoch 32/60\n",
            "305/305 [==============================] - 6s 18ms/step - loss: 0.0909 - accuracy: 0.9670 - val_loss: 0.2495 - val_accuracy: 0.9160\n",
            "Epoch 33/60\n",
            "305/305 [==============================] - 4s 15ms/step - loss: 0.0881 - accuracy: 0.9660 - val_loss: 0.2588 - val_accuracy: 0.9199\n",
            "Epoch 34/60\n",
            "305/305 [==============================] - 4s 15ms/step - loss: 0.0818 - accuracy: 0.9692 - val_loss: 0.2684 - val_accuracy: 0.9154\n",
            "Epoch 35/60\n",
            "305/305 [==============================] - 5s 17ms/step - loss: 0.0779 - accuracy: 0.9704 - val_loss: 0.2859 - val_accuracy: 0.9176\n",
            "Epoch 36/60\n",
            "305/305 [==============================] - 4s 14ms/step - loss: 0.0803 - accuracy: 0.9711 - val_loss: 0.3439 - val_accuracy: 0.9039\n",
            "Epoch 37/60\n",
            "305/305 [==============================] - 4s 15ms/step - loss: 0.0807 - accuracy: 0.9703 - val_loss: 0.2644 - val_accuracy: 0.9224\n",
            "Epoch 38/60\n",
            "305/305 [==============================] - 5s 18ms/step - loss: 0.0752 - accuracy: 0.9723 - val_loss: 0.2888 - val_accuracy: 0.9177\n",
            "Epoch 39/60\n",
            "305/305 [==============================] - 5s 15ms/step - loss: 0.0654 - accuracy: 0.9758 - val_loss: 0.3229 - val_accuracy: 0.9031\n",
            "Epoch 40/60\n",
            "305/305 [==============================] - 4s 15ms/step - loss: 0.0779 - accuracy: 0.9710 - val_loss: 0.2952 - val_accuracy: 0.9120\n",
            "Epoch 41/60\n",
            "305/305 [==============================] - 6s 18ms/step - loss: 0.0946 - accuracy: 0.9665 - val_loss: 0.2988 - val_accuracy: 0.9077\n",
            "Epoch 42/60\n",
            "305/305 [==============================] - 5s 16ms/step - loss: 0.0706 - accuracy: 0.9731 - val_loss: 0.2244 - val_accuracy: 0.9311\n",
            "Epoch 43/60\n",
            "305/305 [==============================] - 4s 15ms/step - loss: 0.0708 - accuracy: 0.9751 - val_loss: 0.3793 - val_accuracy: 0.8931\n",
            "Epoch 44/60\n",
            "305/305 [==============================] - 6s 18ms/step - loss: 0.0557 - accuracy: 0.9790 - val_loss: 0.3557 - val_accuracy: 0.9049\n",
            "Epoch 45/60\n",
            "305/305 [==============================] - 4s 14ms/step - loss: 0.0630 - accuracy: 0.9769 - val_loss: 0.3089 - val_accuracy: 0.9126\n",
            "Epoch 46/60\n",
            "305/305 [==============================] - 4s 15ms/step - loss: 0.0590 - accuracy: 0.9782 - val_loss: 0.2783 - val_accuracy: 0.9242\n",
            "Epoch 47/60\n",
            "305/305 [==============================] - 5s 18ms/step - loss: 0.0608 - accuracy: 0.9774 - val_loss: 0.3007 - val_accuracy: 0.9137\n",
            "Epoch 48/60\n",
            "305/305 [==============================] - 4s 13ms/step - loss: 0.0572 - accuracy: 0.9795 - val_loss: 0.2170 - val_accuracy: 0.9375\n",
            "Epoch 49/60\n",
            "305/305 [==============================] - 5s 15ms/step - loss: 0.0484 - accuracy: 0.9839 - val_loss: 0.3355 - val_accuracy: 0.9079\n",
            "Epoch 50/60\n",
            "305/305 [==============================] - 5s 18ms/step - loss: 0.0457 - accuracy: 0.9838 - val_loss: 0.2680 - val_accuracy: 0.9262\n",
            "Epoch 51/60\n",
            "305/305 [==============================] - 4s 15ms/step - loss: 0.0473 - accuracy: 0.9829 - val_loss: 0.2514 - val_accuracy: 0.9304\n",
            "Epoch 52/60\n",
            "305/305 [==============================] - 5s 15ms/step - loss: 0.0495 - accuracy: 0.9825 - val_loss: 0.2782 - val_accuracy: 0.9193\n",
            "Epoch 53/60\n",
            "305/305 [==============================] - 5s 17ms/step - loss: 0.0493 - accuracy: 0.9825 - val_loss: 0.2602 - val_accuracy: 0.9259\n",
            "Epoch 54/60\n",
            "305/305 [==============================] - 5s 16ms/step - loss: 0.0585 - accuracy: 0.9791 - val_loss: 0.2574 - val_accuracy: 0.9256\n",
            "Epoch 55/60\n",
            "305/305 [==============================] - 4s 15ms/step - loss: 0.0524 - accuracy: 0.9819 - val_loss: 0.2809 - val_accuracy: 0.9262\n",
            "Epoch 56/60\n",
            "305/305 [==============================] - 5s 16ms/step - loss: 0.0486 - accuracy: 0.9826 - val_loss: 0.3305 - val_accuracy: 0.9106\n",
            "Epoch 57/60\n",
            "305/305 [==============================] - 4s 14ms/step - loss: 0.0470 - accuracy: 0.9825 - val_loss: 0.3404 - val_accuracy: 0.9117\n",
            "Epoch 58/60\n",
            "305/305 [==============================] - 5s 15ms/step - loss: 0.0756 - accuracy: 0.9737 - val_loss: 0.2891 - val_accuracy: 0.9180\n",
            "Epoch 59/60\n",
            "305/305 [==============================] - 5s 18ms/step - loss: 0.0514 - accuracy: 0.9814 - val_loss: 0.2558 - val_accuracy: 0.9282\n",
            "Epoch 60/60\n",
            "305/305 [==============================] - 5s 15ms/step - loss: 0.0463 - accuracy: 0.9838 - val_loss: 0.2265 - val_accuracy: 0.9359\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_6 (Conv2D)           (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " activation_8 (Activation)   (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " batch_normalization_7 (Batc  (None, 32, 32, 32)       128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 32, 32, 32)        9248      \n",
            "                                                                 \n",
            " activation_9 (Activation)   (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " batch_normalization_8 (Batc  (None, 32, 32, 32)       128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 16, 16, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 16, 16, 32)        0         \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 16, 16, 64)        18496     \n",
            "                                                                 \n",
            " activation_10 (Activation)  (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " batch_normalization_9 (Batc  (None, 16, 16, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 16, 16, 64)        36928     \n",
            "                                                                 \n",
            " activation_11 (Activation)  (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " batch_normalization_10 (Bat  (None, 16, 16, 64)       256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 8, 8, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 8, 8, 128)         73856     \n",
            "                                                                 \n",
            " activation_12 (Activation)  (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " batch_normalization_11 (Bat  (None, 8, 8, 128)        512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 8, 8, 128)         147584    \n",
            "                                                                 \n",
            " activation_13 (Activation)  (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " batch_normalization_12 (Bat  (None, 8, 8, 128)        512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 4, 4, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 4, 4, 128)         0         \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 2048)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1024)              2098176   \n",
            "                                                                 \n",
            " activation_14 (Activation)  (None, 1024)              0         \n",
            "                                                                 \n",
            " batch_normalization_13 (Bat  (None, 1024)             4096      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 3)                 3075      \n",
            "                                                                 \n",
            " activation_15 (Activation)  (None, 3)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,394,147\n",
            "Trainable params: 2,391,203\n",
            "Non-trainable params: 2,944\n",
            "_________________________________________________________________\n",
            "[INFO]: Đánh giá model....\n",
            "102/102 [==============================] - 1s 4ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         cat       0.91      0.93      0.92      2170\n",
            "         dog       0.91      0.92      0.92      2198\n",
            "       panda       0.99      0.95      0.97      2123\n",
            "\n",
            "    accuracy                           0.94      6491\n",
            "   macro avg       0.94      0.94      0.94      6491\n",
            "weighted avg       0.94      0.94      0.94      6491\n",
            "\n"
          ]
        }
      ]
    }
  ]
}